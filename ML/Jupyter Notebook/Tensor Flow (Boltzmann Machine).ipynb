{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"sep\" helps in seperating the mixed up movie genres.\n",
    "\"header\" as the data set doesn't have any type of headings, we need to name them inorder to use, else we can type \"NONE\"\n",
    "\"engine\" on which platform we want to run the dataset\n",
    "\"encoding\" in order to make the engine understand all types of icons and letters we need to provide an encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/Movies Dataset/ml-1m/movies.dat\", sep = '::', engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/Movies Dataset/ml-1m/users.dat\", sep = '::', engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/Movies Dataset/ml-1m/ratings.dat\", sep = '::', engine = 'python',encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .base be the training set  \n",
    "* .test be the test set\n",
    "* delimiter acts as a seperator to data set. \\t tells the next data to go on to next tab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Column1 = users\n",
    "Column2 = movies\n",
    "Column3 = ratings\n",
    "Column4 = time stamp ( Not Needed to train a model )\n",
    "\n",
    "The column names are as similar to the ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/Movies Dataset/ml-100k/u1.base\", delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting training set in to an array\n",
    "The reason to convert in to array is, in order to use the torch and tensor functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set= pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/Movies Dataset/ml-100k/u1.test\", delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Number of Users & Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps in providing the count of number of movies and number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data in to  array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = [] # To create list #\n",
    "    for id_users in range(1, nb_users + 1): # as we know thst nb_users are 943, the indexing starts from 0 in that time the last variable 943 will get lost, so we added +1 to the list #\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings # This helps in sending the code to the first index value starting at zero rather than sending it to one #\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the data in to Torch tensors.\n",
    "we can even use tensorflow tensors or numpy tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the ratings into binary ratings 1(liked), 0(unliked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nv = number of visisble nodes, nh = number of hidden nodes\n",
    "* W = weights (upper case because we are considering all weights)\n",
    "* p_h_given_v = probability of hidden nodes with given visible nodes\n",
    "* p_v_given_h = probability of visible nodes with given hidden nodes\n",
    "* v0 = visible nodes iteration starting at zero\n",
    "* vk = visible nodes iteration ending at k\n",
    "* t = transpose of matrix\n",
    "* ph = probability of hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100 # the batch size can be tunable till 943, because there are 943 lists in data frame. We can change it till we get the best tuned response #\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.3713)\n",
      "epoch: 2 loss: tensor(0.2534)\n",
      "epoch: 3 loss: tensor(0.2538)\n",
      "epoch: 4 loss: tensor(0.2354)\n",
      "epoch: 5 loss: tensor(0.2478)\n",
      "epoch: 6 loss: tensor(0.2481)\n",
      "epoch: 7 loss: tensor(0.2491)\n",
      "epoch: 8 loss: tensor(0.2481)\n",
      "epoch: 9 loss: tensor(0.2454)\n",
      "epoch: 10 loss: tensor(0.2466)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "s = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2422)\n"
     ]
    }
   ],
   "source": [
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
