{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"G:/Education/Machine Learning/ML_CSV_FILES/sonar_mines_rocks.csv\")\n",
    "    x = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    print(x.shape)\n",
    "    return(x, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels)) \n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n"
     ]
    }
   ],
   "source": [
    "x,Y = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,Y = shuffle(x,Y,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,Y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 60)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 60\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 1000 # NUMBER OF ITERATIONS TO REDUCE THE ERROR #\n",
    "cost_history = np.empty(shape = [1], dtype = float)\n",
    "n_dim = x.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2\n",
    "model_path = \"C:/Users/varun/Machine Learning/Tensorflow Implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\varun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "w = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perception(x, weights, biases):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3' : tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4' : tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out' : tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1' : tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3' : tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4' : tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out' : tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multilayer_perception(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-91e01b88e989>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_history = []\n",
    "accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 144.38297 -MSE: 18927.735378561483 -Train Accuracy: 0.44848484\n",
      "epoch: 1 - cost: 7.9093637 -MSE: 153.540676020119 -Train Accuracy: 0.55151516\n",
      "epoch: 2 - cost: 8.181445 -MSE: 67.76643356520339 -Train Accuracy: 0.44848484\n",
      "epoch: 3 - cost: 0.75950843 -MSE: 0.586993978735078 -Train Accuracy: 0.4060606\n",
      "epoch: 4 - cost: 0.7305318 -MSE: 0.45555897851307575 -Train Accuracy: 0.55151516\n",
      "epoch: 5 - cost: 0.72252333 -MSE: 0.33865257230376616 -Train Accuracy: 0.35757574\n",
      "epoch: 6 - cost: 0.7128855 -MSE: 0.3955744941794573 -Train Accuracy: 0.55757576\n",
      "epoch: 7 - cost: 0.7089563 -MSE: 0.32621008710952876 -Train Accuracy: 0.4121212\n",
      "epoch: 8 - cost: 0.7057492 -MSE: 0.38007391927171535 -Train Accuracy: 0.55151516\n",
      "epoch: 9 - cost: 0.7033197 -MSE: 0.3524095072749922 -Train Accuracy: 0.53333336\n",
      "epoch: 10 - cost: 0.701275 -MSE: 0.38398580512192854 -Train Accuracy: 0.55151516\n",
      "epoch: 11 - cost: 0.6984495 -MSE: 0.3743477326968686 -Train Accuracy: 0.56363636\n",
      "epoch: 12 - cost: 0.6931073 -MSE: 0.385361229078615 -Train Accuracy: 0.56969696\n",
      "epoch: 13 - cost: 0.68903196 -MSE: 0.37379824889304825 -Train Accuracy: 0.58181816\n",
      "epoch: 14 - cost: 0.67905086 -MSE: 0.34973910455668766 -Train Accuracy: 0.58181816\n",
      "epoch: 15 - cost: 0.678495 -MSE: 0.3314915120788691 -Train Accuracy: 0.5939394\n",
      "epoch: 16 - cost: 0.7442715 -MSE: 0.7833828894398439 -Train Accuracy: 0.55151516\n",
      "epoch: 17 - cost: 0.72725344 -MSE: 0.306112952528209 -Train Accuracy: 0.44848484\n",
      "epoch: 18 - cost: 0.69430876 -MSE: 0.4935753462738182 -Train Accuracy: 0.55757576\n",
      "epoch: 19 - cost: 0.686239 -MSE: 0.30767043460968607 -Train Accuracy: 0.56363636\n",
      "epoch: 20 - cost: 0.68886167 -MSE: 0.491111767020256 -Train Accuracy: 0.56363636\n",
      "epoch: 21 - cost: 0.7622678 -MSE: 0.38151851266310904 -Train Accuracy: 0.44848484\n",
      "epoch: 22 - cost: 0.88400537 -MSE: 1.4945779663904193 -Train Accuracy: 0.55151516\n",
      "epoch: 23 - cost: 0.7717225 -MSE: 0.3662497568733858 -Train Accuracy: 0.44848484\n",
      "epoch: 24 - cost: 0.6976826 -MSE: 0.3944213646857418 -Train Accuracy: 0.46666667\n",
      "epoch: 25 - cost: 0.6938537 -MSE: 0.48340866981591596 -Train Accuracy: 0.55151516\n",
      "epoch: 26 - cost: 0.6922373 -MSE: 0.4842251575306468 -Train Accuracy: 0.55757576\n",
      "epoch: 27 - cost: 0.69081706 -MSE: 0.5094993169840764 -Train Accuracy: 0.55151516\n",
      "epoch: 28 - cost: 0.6894554 -MSE: 0.5273143733547546 -Train Accuracy: 0.55151516\n",
      "epoch: 29 - cost: 0.68812853 -MSE: 0.5466336678022226 -Train Accuracy: 0.55151516\n",
      "epoch: 30 - cost: 0.68684006 -MSE: 0.5615649283550161 -Train Accuracy: 0.55151516\n",
      "epoch: 31 - cost: 0.68557 -MSE: 0.5750967636833103 -Train Accuracy: 0.55151516\n",
      "epoch: 32 - cost: 0.6843344 -MSE: 0.585673664692658 -Train Accuracy: 0.55151516\n",
      "epoch: 33 - cost: 0.6831549 -MSE: 0.5940616679573881 -Train Accuracy: 0.55757576\n",
      "epoch: 34 - cost: 0.6819949 -MSE: 0.5998528097239687 -Train Accuracy: 0.55757576\n",
      "epoch: 35 - cost: 0.68084294 -MSE: 0.603906019840301 -Train Accuracy: 0.55757576\n",
      "epoch: 36 - cost: 0.6797136 -MSE: 0.6070612777017175 -Train Accuracy: 0.56363636\n",
      "epoch: 37 - cost: 0.6785799 -MSE: 0.6093694417853117 -Train Accuracy: 0.56969696\n",
      "epoch: 38 - cost: 0.67740244 -MSE: 0.6107100278316175 -Train Accuracy: 0.56969696\n",
      "epoch: 39 - cost: 0.67616594 -MSE: 0.611992002945484 -Train Accuracy: 0.58181816\n",
      "epoch: 40 - cost: 0.674878 -MSE: 0.6108034907859733 -Train Accuracy: 0.58181816\n",
      "epoch: 41 - cost: 0.67329663 -MSE: 0.6011394996814209 -Train Accuracy: 0.58787876\n",
      "epoch: 42 - cost: 0.6714764 -MSE: 0.5855011965340632 -Train Accuracy: 0.5939394\n",
      "epoch: 43 - cost: 0.66914266 -MSE: 0.5571471318953334 -Train Accuracy: 0.57575756\n",
      "epoch: 44 - cost: 0.6668484 -MSE: 0.5214857249063993 -Train Accuracy: 0.57575756\n",
      "epoch: 45 - cost: 0.664673 -MSE: 0.47623731794833113 -Train Accuracy: 0.58787876\n",
      "epoch: 46 - cost: 0.66236764 -MSE: 0.44426270668889095 -Train Accuracy: 0.58787876\n",
      "epoch: 47 - cost: 0.65999657 -MSE: 0.40890294452059756 -Train Accuracy: 0.58787876\n",
      "epoch: 48 - cost: 0.6576605 -MSE: 0.3897077377585457 -Train Accuracy: 0.6\n",
      "epoch: 49 - cost: 0.655283 -MSE: 0.36408452296417626 -Train Accuracy: 0.6121212\n",
      "epoch: 50 - cost: 0.6528487 -MSE: 0.3589828832863337 -Train Accuracy: 0.5939394\n",
      "epoch: 51 - cost: 0.6503798 -MSE: 0.33063214578374533 -Train Accuracy: 0.6606061\n",
      "epoch: 52 - cost: 0.6479593 -MSE: 0.3397575712594343 -Train Accuracy: 0.6\n",
      "epoch: 53 - cost: 0.6460944 -MSE: 0.29748307741578445 -Train Accuracy: 0.6848485\n",
      "epoch: 54 - cost: 0.6468144 -MSE: 0.353657867779617 -Train Accuracy: 0.58181816\n",
      "epoch: 55 - cost: 0.6584724 -MSE: 0.27574303525446503 -Train Accuracy: 0.6242424\n",
      "epoch: 56 - cost: 0.71378314 -MSE: 0.6042348545148906 -Train Accuracy: 0.55757576\n",
      "epoch: 57 - cost: 0.8500346 -MSE: 0.64845038806917 -Train Accuracy: 0.44848484\n",
      "epoch: 58 - cost: 0.9111947 -MSE: 1.1067106206897575 -Train Accuracy: 0.55151516\n",
      "epoch: 59 - cost: 0.76264495 -MSE: 0.4111864256922943 -Train Accuracy: 0.44848484\n",
      "epoch: 60 - cost: 0.66246396 -MSE: 0.3850272882049553 -Train Accuracy: 0.6848485\n",
      "epoch: 61 - cost: 0.6569106 -MSE: 0.4064710052175243 -Train Accuracy: 0.58787876\n",
      "epoch: 62 - cost: 0.65425646 -MSE: 0.38256024430632135 -Train Accuracy: 0.6060606\n",
      "epoch: 63 - cost: 0.651792 -MSE: 0.37777344121929257 -Train Accuracy: 0.6121212\n",
      "epoch: 64 - cost: 0.6492569 -MSE: 0.36589441495177805 -Train Accuracy: 0.6181818\n",
      "epoch: 65 - cost: 0.64626104 -MSE: 0.3532018217081013 -Train Accuracy: 0.630303\n",
      "epoch: 66 - cost: 0.6425207 -MSE: 0.3394455091871965 -Train Accuracy: 0.6606061\n",
      "epoch: 67 - cost: 0.6374847 -MSE: 0.3277649770321632 -Train Accuracy: 0.6545454\n",
      "epoch: 68 - cost: 0.63294107 -MSE: 0.3360185998197346 -Train Accuracy: 0.6666667\n",
      "epoch: 69 - cost: 0.62879336 -MSE: 0.35375162663651155 -Train Accuracy: 0.6727273\n",
      "epoch: 70 - cost: 0.6238328 -MSE: 0.3973324518458672 -Train Accuracy: 0.6909091\n",
      "epoch: 71 - cost: 0.61955976 -MSE: 0.4453571119595919 -Train Accuracy: 0.6787879\n",
      "epoch: 72 - cost: 0.6161675 -MSE: 0.5074076550352506 -Train Accuracy: 0.6787879\n",
      "epoch: 73 - cost: 0.6153597 -MSE: 0.5310623979182585 -Train Accuracy: 0.6666667\n",
      "epoch: 74 - cost: 0.6248862 -MSE: 0.6837375883390715 -Train Accuracy: 0.6606061\n",
      "epoch: 75 - cost: 0.6827788 -MSE: 0.7280172232099249 -Train Accuracy: 0.58787876\n",
      "epoch: 76 - cost: 0.8598975 -MSE: 1.5621989684677569 -Train Accuracy: 0.44848484\n",
      "epoch: 77 - cost: 0.9762409 -MSE: 1.895769690693025 -Train Accuracy: 0.55151516\n",
      "epoch: 78 - cost: 0.74916273 -MSE: 0.7894080508105868 -Train Accuracy: 0.44848484\n",
      "epoch: 79 - cost: 0.65364724 -MSE: 0.7496926127983021 -Train Accuracy: 0.6969697\n",
      "epoch: 80 - cost: 0.64020294 -MSE: 0.7749868599828585 -Train Accuracy: 0.6545454\n",
      "epoch: 81 - cost: 0.63466686 -MSE: 0.7276860823413428 -Train Accuracy: 0.6848485\n",
      "epoch: 82 - cost: 0.62857634 -MSE: 0.7031910214305397 -Train Accuracy: 0.6787879\n",
      "epoch: 83 - cost: 0.6224857 -MSE: 0.6903470970057716 -Train Accuracy: 0.6787879\n",
      "epoch: 84 - cost: 0.6170681 -MSE: 0.685817253870353 -Train Accuracy: 0.6727273\n",
      "epoch: 85 - cost: 0.6102436 -MSE: 0.7400843388738733 -Train Accuracy: 0.6848485\n",
      "epoch: 86 - cost: 0.6037436 -MSE: 0.8473347662041225 -Train Accuracy: 0.6909091\n",
      "epoch: 87 - cost: 0.59842646 -MSE: 0.9570331199923662 -Train Accuracy: 0.6848485\n",
      "epoch: 88 - cost: 0.593981 -MSE: 1.0116972553858277 -Train Accuracy: 0.6848485\n",
      "epoch: 89 - cost: 0.5902944 -MSE: 1.0942325410839469 -Train Accuracy: 0.6969697\n",
      "epoch: 90 - cost: 0.58880895 -MSE: 1.0770938109569694 -Train Accuracy: 0.6848485\n",
      "epoch: 91 - cost: 0.5994223 -MSE: 1.3405286334671247 -Train Accuracy: 0.6969697\n",
      "epoch: 92 - cost: 0.6822632 -MSE: 1.1791422983564221 -Train Accuracy: 0.58787876\n",
      "epoch: 93 - cost: 0.999968 -MSE: 3.5107589615992016 -Train Accuracy: 0.44848484\n",
      "epoch: 94 - cost: 1.0051842 -MSE: 2.228809739525034 -Train Accuracy: 0.55151516\n",
      "epoch: 95 - cost: 0.7202501 -MSE: 0.8523913598946967 -Train Accuracy: 0.44848484\n",
      "epoch: 96 - cost: 0.6479999 -MSE: 0.8643857455479701 -Train Accuracy: 0.6969697\n",
      "epoch: 97 - cost: 0.63326395 -MSE: 0.9043835587489575 -Train Accuracy: 0.6666667\n",
      "epoch: 98 - cost: 0.62773025 -MSE: 0.8940770858977785 -Train Accuracy: 0.6787879\n",
      "epoch: 99 - cost: 0.62099814 -MSE: 0.8901122985744481 -Train Accuracy: 0.6969697\n",
      "epoch: 100 - cost: 0.613961 -MSE: 0.9019880465795095 -Train Accuracy: 0.7030303\n",
      "epoch: 101 - cost: 0.60699505 -MSE: 0.9332080068097733 -Train Accuracy: 0.7090909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102 - cost: 0.5998322 -MSE: 0.9957509823924502 -Train Accuracy: 0.72727275\n",
      "epoch: 103 - cost: 0.59226346 -MSE: 1.1549353865118848 -Train Accuracy: 0.72727275\n",
      "epoch: 104 - cost: 0.5835453 -MSE: 1.376688110784863 -Train Accuracy: 0.7151515\n",
      "epoch: 105 - cost: 0.57536715 -MSE: 1.6040324818119849 -Train Accuracy: 0.72121215\n",
      "epoch: 106 - cost: 0.5683332 -MSE: 1.8022269769211716 -Train Accuracy: 0.7030303\n",
      "epoch: 107 - cost: 0.56213367 -MSE: 1.8996447458430048 -Train Accuracy: 0.73333335\n",
      "epoch: 108 - cost: 0.55686176 -MSE: 2.1339308484876254 -Train Accuracy: 0.72727275\n",
      "epoch: 109 - cost: 0.55524665 -MSE: 2.070331565668906 -Train Accuracy: 0.73939395\n",
      "epoch: 110 - cost: 0.5842838 -MSE: 3.0073003029358976 -Train Accuracy: 0.7090909\n",
      "epoch: 111 - cost: 0.82526696 -MSE: 2.0972029696770327 -Train Accuracy: 0.55151516\n",
      "epoch: 112 - cost: 1.0623915 -MSE: 8.44211754732026 -Train Accuracy: 0.44848484\n",
      "epoch: 113 - cost: 0.6749465 -MSE: 0.6109756627521702 -Train Accuracy: 0.57575756\n",
      "epoch: 114 - cost: 0.5994241 -MSE: 0.5935689814794239 -Train Accuracy: 0.72121215\n",
      "epoch: 115 - cost: 0.59102803 -MSE: 0.6421258579317284 -Train Accuracy: 0.72727275\n",
      "epoch: 116 - cost: 0.583223 -MSE: 0.7402962080838178 -Train Accuracy: 0.72727275\n",
      "epoch: 117 - cost: 0.5753752 -MSE: 0.8413899299005771 -Train Accuracy: 0.75151515\n",
      "epoch: 118 - cost: 0.5665328 -MSE: 0.9914374339051244 -Train Accuracy: 0.74545455\n",
      "epoch: 119 - cost: 0.5571727 -MSE: 1.2429553159301412 -Train Accuracy: 0.75151515\n",
      "epoch: 120 - cost: 0.5470872 -MSE: 1.5457398247898095 -Train Accuracy: 0.75151515\n",
      "epoch: 121 - cost: 0.5376379 -MSE: 1.957883373055348 -Train Accuracy: 0.74545455\n",
      "epoch: 122 - cost: 0.53011715 -MSE: 2.1059331573436233 -Train Accuracy: 0.75757575\n",
      "epoch: 123 - cost: 0.5393436 -MSE: 2.8612985473166037 -Train Accuracy: 0.75151515\n",
      "epoch: 124 - cost: 0.69314075 -MSE: 2.2898631202017863 -Train Accuracy: 0.6181818\n",
      "epoch: 125 - cost: 1.0560312 -MSE: 10.146377870041162 -Train Accuracy: 0.44848484\n",
      "epoch: 126 - cost: 0.671385 -MSE: 0.8955618379577298 -Train Accuracy: 0.57575756\n",
      "epoch: 127 - cost: 0.60752136 -MSE: 0.694384612444893 -Train Accuracy: 0.76969695\n",
      "epoch: 128 - cost: 0.5993837 -MSE: 0.8907334749562462 -Train Accuracy: 0.6484848\n",
      "epoch: 129 - cost: 0.6452353 -MSE: 1.2735496223844236 -Train Accuracy: 0.6060606\n",
      "epoch: 130 - cost: 0.5825319 -MSE: 1.0359163973618688 -Train Accuracy: 0.6848485\n",
      "epoch: 131 - cost: 0.63923955 -MSE: 1.7963970898885067 -Train Accuracy: 0.6\n",
      "epoch: 132 - cost: 0.6202754 -MSE: 1.3373481816425772 -Train Accuracy: 0.6545454\n",
      "epoch: 133 - cost: 0.7030676 -MSE: 3.168396139281051 -Train Accuracy: 0.5030303\n",
      "epoch: 134 - cost: 0.56337 -MSE: 1.1600873227652049 -Train Accuracy: 0.7878788\n",
      "epoch: 135 - cost: 0.56980556 -MSE: 1.3704364033917882 -Train Accuracy: 0.7030303\n",
      "epoch: 136 - cost: 0.6396478 -MSE: 2.8638452754852506 -Train Accuracy: 0.6\n",
      "epoch: 137 - cost: 0.6466153 -MSE: 1.6300726107812518 -Train Accuracy: 0.6484848\n",
      "epoch: 138 - cost: 0.7267985 -MSE: 4.364144899542971 -Train Accuracy: 0.46666667\n",
      "epoch: 139 - cost: 0.5742623 -MSE: 1.1093893887702768 -Train Accuracy: 0.76363635\n",
      "epoch: 140 - cost: 0.5651637 -MSE: 1.2987545392799764 -Train Accuracy: 0.7090909\n",
      "epoch: 141 - cost: 0.5881199 -MSE: 2.3661398906314473 -Train Accuracy: 0.7151515\n",
      "epoch: 142 - cost: 0.6231529 -MSE: 1.768494081282216 -Train Accuracy: 0.6606061\n",
      "epoch: 143 - cost: 0.718726 -MSE: 5.064997166303757 -Train Accuracy: 0.5212121\n",
      "epoch: 144 - cost: 0.5524988 -MSE: 1.0383874678019145 -Train Accuracy: 0.74545455\n",
      "epoch: 145 - cost: 0.5381676 -MSE: 1.3393425660380736 -Train Accuracy: 0.74545455\n",
      "epoch: 146 - cost: 0.5255047 -MSE: 1.852079794660173 -Train Accuracy: 0.76969695\n",
      "epoch: 147 - cost: 0.5222556 -MSE: 2.201882124488965 -Train Accuracy: 0.74545455\n",
      "epoch: 148 - cost: 0.57594085 -MSE: 4.712191122804181 -Train Accuracy: 0.6848485\n",
      "epoch: 149 - cost: 0.8525119 -MSE: 2.75300897211314 -Train Accuracy: 0.55757576\n",
      "epoch: 150 - cost: 0.86828357 -MSE: 9.55721435106421 -Train Accuracy: 0.44848484\n",
      "epoch: 151 - cost: 0.65367347 -MSE: 0.9156489253739036 -Train Accuracy: 0.6\n",
      "epoch: 152 - cost: 0.582897 -MSE: 0.9118541752493178 -Train Accuracy: 0.7818182\n",
      "epoch: 153 - cost: 0.56104517 -MSE: 1.1310518145097403 -Train Accuracy: 0.73333335\n",
      "epoch: 154 - cost: 0.55108 -MSE: 1.4600650829976511 -Train Accuracy: 0.77575755\n",
      "epoch: 155 - cost: 0.5418526 -MSE: 1.7089375371561804 -Train Accuracy: 0.73939395\n",
      "epoch: 156 - cost: 0.5419712 -MSE: 2.6546747682306653 -Train Accuracy: 0.77575755\n",
      "epoch: 157 - cost: 0.5463018 -MSE: 2.324221500170822 -Train Accuracy: 0.72727275\n",
      "epoch: 158 - cost: 0.6319774 -MSE: 5.311352514311603 -Train Accuracy: 0.6121212\n",
      "epoch: 159 - cost: 0.6918564 -MSE: 2.1533501128624133 -Train Accuracy: 0.6424242\n",
      "epoch: 160 - cost: 0.71297497 -MSE: 5.644892695234755 -Train Accuracy: 0.47878787\n",
      "epoch: 161 - cost: 0.5597397 -MSE: 1.342628586885912 -Train Accuracy: 0.8\n",
      "epoch: 162 - cost: 0.536472 -MSE: 1.5588880177463071 -Train Accuracy: 0.73939395\n",
      "epoch: 163 - cost: 0.5266622 -MSE: 2.2552433740472133 -Train Accuracy: 0.7818182\n",
      "epoch: 164 - cost: 0.5223139 -MSE: 2.4083365802683163 -Train Accuracy: 0.75151515\n",
      "epoch: 165 - cost: 0.55096155 -MSE: 4.653658312555071 -Train Accuracy: 0.73939395\n",
      "epoch: 166 - cost: 0.70808804 -MSE: 2.6047804443913907 -Train Accuracy: 0.6545454\n",
      "epoch: 167 - cost: 0.77068585 -MSE: 7.855564983317875 -Train Accuracy: 0.46666667\n",
      "epoch: 168 - cost: 0.55692846 -MSE: 1.063176571216809 -Train Accuracy: 0.75757575\n",
      "epoch: 169 - cost: 0.53729135 -MSE: 1.3880498575038405 -Train Accuracy: 0.75757575\n",
      "epoch: 170 - cost: 0.5203259 -MSE: 1.8533724925616535 -Train Accuracy: 0.75151515\n",
      "epoch: 171 - cost: 0.5035499 -MSE: 2.348211468377304 -Train Accuracy: 0.74545455\n",
      "epoch: 172 - cost: 0.48965815 -MSE: 3.264691449132613 -Train Accuracy: 0.77575755\n",
      "epoch: 173 - cost: 0.48104608 -MSE: 3.6929640279809166 -Train Accuracy: 0.76363635\n",
      "epoch: 174 - cost: 0.50973827 -MSE: 6.135782687134257 -Train Accuracy: 0.7818182\n",
      "epoch: 175 - cost: 0.8185031 -MSE: 3.540568355319524 -Train Accuracy: 0.6060606\n",
      "epoch: 176 - cost: 0.97853184 -MSE: 14.040867541606794 -Train Accuracy: 0.44848484\n",
      "epoch: 177 - cost: 0.5991416 -MSE: 0.7274731414530526 -Train Accuracy: 0.8121212\n",
      "epoch: 178 - cost: 0.56638986 -MSE: 1.0468146689306552 -Train Accuracy: 0.73939395\n",
      "epoch: 179 - cost: 0.55628526 -MSE: 0.9823320778840857 -Train Accuracy: 0.76969695\n",
      "epoch: 180 - cost: 0.54018843 -MSE: 1.2409939021536402 -Train Accuracy: 0.75151515\n",
      "epoch: 181 - cost: 0.52779484 -MSE: 1.4235068841366636 -Train Accuracy: 0.76969695\n",
      "epoch: 182 - cost: 0.51527375 -MSE: 1.724981177913549 -Train Accuracy: 0.75757575\n",
      "epoch: 183 - cost: 0.5132637 -MSE: 2.1685095822923333 -Train Accuracy: 0.8242424\n",
      "epoch: 184 - cost: 0.5212752 -MSE: 2.5220280511459343 -Train Accuracy: 0.75151515\n",
      "epoch: 185 - cost: 0.5886932 -MSE: 4.598277153462898 -Train Accuracy: 0.6545454\n",
      "epoch: 186 - cost: 0.6702288 -MSE: 2.831692761465262 -Train Accuracy: 0.6666667\n",
      "epoch: 187 - cost: 0.74673563 -MSE: 7.352920169365846 -Train Accuracy: 0.46666667\n",
      "epoch: 188 - cost: 0.5392329 -MSE: 1.5711689484130067 -Train Accuracy: 0.8181818\n",
      "epoch: 189 - cost: 0.51572424 -MSE: 1.8673467923102223 -Train Accuracy: 0.75151515\n",
      "epoch: 190 - cost: 0.51161295 -MSE: 2.6487607633440944 -Train Accuracy: 0.8242424\n",
      "epoch: 191 - cost: 0.500875 -MSE: 2.776123604114748 -Train Accuracy: 0.75151515\n",
      "epoch: 192 - cost: 0.531765 -MSE: 4.850029816693687 -Train Accuracy: 0.74545455\n",
      "epoch: 193 - cost: 0.6394236 -MSE: 3.1243801196478143 -Train Accuracy: 0.6848485\n",
      "epoch: 194 - cost: 0.76152915 -MSE: 9.498667410331564 -Train Accuracy: 0.5151515\n",
      "epoch: 195 - cost: 0.52229804 -MSE: 1.511959329712808 -Train Accuracy: 0.7818182\n",
      "epoch: 196 - cost: 0.5044646 -MSE: 1.9557801791444258 -Train Accuracy: 0.7818182\n",
      "epoch: 197 - cost: 0.4898452 -MSE: 2.4662646848715313 -Train Accuracy: 0.76363635\n",
      "epoch: 198 - cost: 0.47552097 -MSE: 3.0440894629074116 -Train Accuracy: 0.77575755\n",
      "epoch: 199 - cost: 0.4623751 -MSE: 3.7526399015645624 -Train Accuracy: 0.77575755\n",
      "epoch: 200 - cost: 0.45010468 -MSE: 4.618512868267389 -Train Accuracy: 0.77575755\n",
      "epoch: 201 - cost: 0.44002005 -MSE: 5.430268799070749 -Train Accuracy: 0.7939394\n",
      "epoch: 202 - cost: 0.43277213 -MSE: 6.039186249788176 -Train Accuracy: 0.76969695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 203 - cost: 0.44327393 -MSE: 7.714214429064795 -Train Accuracy: 0.8181818\n",
      "epoch: 204 - cost: 0.6797362 -MSE: 4.724121644788314 -Train Accuracy: 0.6848485\n",
      "epoch: 205 - cost: 1.3594639 -MSE: 25.241825473286543 -Train Accuracy: 0.44848484\n",
      "epoch: 206 - cost: 0.555026 -MSE: 0.7352426213976513 -Train Accuracy: 0.8181818\n",
      "epoch: 207 - cost: 0.54222316 -MSE: 1.07571595385587 -Train Accuracy: 0.75151515\n",
      "epoch: 208 - cost: 0.53353095 -MSE: 0.8930403744666476 -Train Accuracy: 0.8181818\n",
      "epoch: 209 - cost: 0.5376759 -MSE: 1.3450221494366394 -Train Accuracy: 0.74545455\n",
      "epoch: 210 - cost: 0.5706565 -MSE: 0.9131458135450389 -Train Accuracy: 0.75757575\n",
      "epoch: 211 - cost: 0.58009416 -MSE: 1.7691635985998655 -Train Accuracy: 0.6909091\n",
      "epoch: 212 - cost: 0.6371935 -MSE: 1.115338358614957 -Train Accuracy: 0.6121212\n",
      "epoch: 213 - cost: 0.5049454 -MSE: 1.1011901916650846 -Train Accuracy: 0.7939394\n",
      "epoch: 214 - cost: 0.50234306 -MSE: 1.3344373911877487 -Train Accuracy: 0.7878788\n",
      "epoch: 215 - cost: 0.5172421 -MSE: 1.146615140434813 -Train Accuracy: 0.7939394\n",
      "epoch: 216 - cost: 0.55525476 -MSE: 1.875665619700491 -Train Accuracy: 0.7151515\n",
      "epoch: 217 - cost: 0.64962703 -MSE: 1.8805382196967406 -Train Accuracy: 0.5939394\n",
      "epoch: 218 - cost: 0.48458806 -MSE: 1.4520386541395254 -Train Accuracy: 0.8424242\n",
      "epoch: 219 - cost: 0.49068922 -MSE: 1.7841777860324983 -Train Accuracy: 0.77575755\n",
      "epoch: 220 - cost: 0.5499752 -MSE: 2.3763674101634926 -Train Accuracy: 0.7090909\n",
      "epoch: 221 - cost: 0.5955851 -MSE: 2.5587779771395143 -Train Accuracy: 0.6969697\n",
      "epoch: 222 - cost: 0.74312 -MSE: 5.84896819532504 -Train Accuracy: 0.4969697\n",
      "epoch: 223 - cost: 0.5136909 -MSE: 1.476671735950144 -Train Accuracy: 0.8181818\n",
      "epoch: 224 - cost: 0.5454158 -MSE: 1.9252526253081192 -Train Accuracy: 0.72121215\n",
      "epoch: 225 - cost: 0.62036675 -MSE: 3.7215959121619258 -Train Accuracy: 0.6060606\n",
      "epoch: 226 - cost: 0.4681034 -MSE: 1.9324114875908394 -Train Accuracy: 0.7939394\n",
      "epoch: 227 - cost: 0.45801553 -MSE: 2.5121016314724764 -Train Accuracy: 0.8060606\n",
      "epoch: 228 - cost: 0.45424017 -MSE: 2.72952459902017 -Train Accuracy: 0.8\n",
      "epoch: 229 - cost: 0.49525017 -MSE: 4.44148986243746 -Train Accuracy: 0.76969695\n",
      "epoch: 230 - cost: 0.7212072 -MSE: 3.4700508802774768 -Train Accuracy: 0.6727273\n",
      "epoch: 231 - cost: 0.913005 -MSE: 12.16090270386616 -Train Accuracy: 0.46666667\n",
      "epoch: 232 - cost: 0.5814335 -MSE: 1.0241774625685887 -Train Accuracy: 0.6969697\n",
      "epoch: 233 - cost: 0.50280046 -MSE: 1.0952055129241602 -Train Accuracy: 0.7878788\n",
      "epoch: 234 - cost: 0.48821393 -MSE: 1.5005891833236458 -Train Accuracy: 0.8424242\n",
      "epoch: 235 - cost: 0.47979912 -MSE: 1.858969904324166 -Train Accuracy: 0.7818182\n",
      "epoch: 236 - cost: 0.4939062 -MSE: 2.7655132340193083 -Train Accuracy: 0.7878788\n",
      "epoch: 237 - cost: 0.5531671 -MSE: 2.6997784864021876 -Train Accuracy: 0.7151515\n",
      "epoch: 238 - cost: 0.65105784 -MSE: 6.283633620725484 -Train Accuracy: 0.5939394\n",
      "epoch: 239 - cost: 0.47236004 -MSE: 1.7244845802196014 -Train Accuracy: 0.8\n",
      "epoch: 240 - cost: 0.46321288 -MSE: 2.5807631426341153 -Train Accuracy: 0.8363636\n",
      "epoch: 241 - cost: 0.45437026 -MSE: 2.603386190569939 -Train Accuracy: 0.8\n",
      "epoch: 242 - cost: 0.4926674 -MSE: 4.3710855748397295 -Train Accuracy: 0.76969695\n",
      "epoch: 243 - cost: 0.6405004 -MSE: 3.2067689192897677 -Train Accuracy: 0.6969697\n",
      "epoch: 244 - cost: 0.8148854 -MSE: 10.481568969833356 -Train Accuracy: 0.5151515\n",
      "epoch: 245 - cost: 0.49326584 -MSE: 1.1010217589313767 -Train Accuracy: 0.8060606\n",
      "epoch: 246 - cost: 0.47237924 -MSE: 1.5472198639948416 -Train Accuracy: 0.7939394\n",
      "epoch: 247 - cost: 0.45735925 -MSE: 2.0157428908649004 -Train Accuracy: 0.8242424\n",
      "epoch: 248 - cost: 0.44393793 -MSE: 2.3648286107307177 -Train Accuracy: 0.7878788\n",
      "epoch: 249 - cost: 0.43245128 -MSE: 2.924024861173293 -Train Accuracy: 0.8242424\n",
      "epoch: 250 - cost: 0.4238051 -MSE: 3.163152690746013 -Train Accuracy: 0.7818182\n",
      "epoch: 251 - cost: 0.42634216 -MSE: 4.274882246021726 -Train Accuracy: 0.8363636\n",
      "epoch: 252 - cost: 0.47179043 -MSE: 3.561634915933452 -Train Accuracy: 0.7818182\n",
      "epoch: 253 - cost: 0.73733413 -MSE: 9.97332084946288 -Train Accuracy: 0.6\n",
      "epoch: 254 - cost: 0.67531836 -MSE: 2.2921998257233973 -Train Accuracy: 0.6787879\n",
      "epoch: 255 - cost: 0.6758486 -MSE: 4.278993970181286 -Train Accuracy: 0.5272727\n",
      "epoch: 256 - cost: 0.5535512 -MSE: 1.7619800895658813 -Train Accuracy: 0.6969697\n",
      "epoch: 257 - cost: 0.46215847 -MSE: 1.5823110091859445 -Train Accuracy: 0.8121212\n",
      "epoch: 258 - cost: 0.442081 -MSE: 2.440661386775376 -Train Accuracy: 0.8545455\n",
      "epoch: 259 - cost: 0.42764217 -MSE: 2.7448392587730814 -Train Accuracy: 0.8060606\n",
      "epoch: 260 - cost: 0.42005768 -MSE: 3.792470762737855 -Train Accuracy: 0.8424242\n",
      "epoch: 261 - cost: 0.4264034 -MSE: 3.511458915338494 -Train Accuracy: 0.8060606\n",
      "epoch: 262 - cost: 0.5424138 -MSE: 7.259865090748874 -Train Accuracy: 0.7030303\n",
      "epoch: 263 - cost: 0.95338243 -MSE: 4.054261785469224 -Train Accuracy: 0.5939394\n",
      "epoch: 264 - cost: 0.83114004 -MSE: 9.85834057514476 -Train Accuracy: 0.46060607\n",
      "epoch: 265 - cost: 0.5922231 -MSE: 1.0459175244845562 -Train Accuracy: 0.6969697\n",
      "epoch: 266 - cost: 0.5056335 -MSE: 1.1556444389427365 -Train Accuracy: 0.8242424\n",
      "epoch: 267 - cost: 0.47850415 -MSE: 1.542892574512513 -Train Accuracy: 0.8121212\n",
      "epoch: 268 - cost: 0.45606667 -MSE: 1.9203563124972955 -Train Accuracy: 0.8060606\n",
      "epoch: 269 - cost: 0.43674746 -MSE: 2.3465084224355564 -Train Accuracy: 0.8060606\n",
      "epoch: 270 - cost: 0.4219472 -MSE: 2.7916071609965964 -Train Accuracy: 0.8060606\n",
      "epoch: 271 - cost: 0.40984833 -MSE: 3.2776129449534315 -Train Accuracy: 0.8181818\n",
      "epoch: 272 - cost: 0.3986389 -MSE: 3.761404895103806 -Train Accuracy: 0.8181818\n",
      "epoch: 273 - cost: 0.38954115 -MSE: 4.307570325038925 -Train Accuracy: 0.8424242\n",
      "epoch: 274 - cost: 0.38276422 -MSE: 4.647245203995436 -Train Accuracy: 0.8242424\n",
      "epoch: 275 - cost: 0.38713562 -MSE: 5.845142628387327 -Train Accuracy: 0.8484849\n",
      "epoch: 276 - cost: 0.5273803 -MSE: 4.309302328047168 -Train Accuracy: 0.73939395\n",
      "epoch: 277 - cost: 1.1516614 -MSE: 18.7859086007114 -Train Accuracy: 0.53333336\n",
      "epoch: 278 - cost: 0.7231143 -MSE: 2.0682136433449765 -Train Accuracy: 0.6181818\n",
      "epoch: 279 - cost: 0.63499546 -MSE: 1.133558906811628 -Train Accuracy: 0.5939394\n",
      "epoch: 280 - cost: 0.54899174 -MSE: 1.0363226993650958 -Train Accuracy: 0.77575755\n",
      "epoch: 281 - cost: 0.47503275 -MSE: 1.3384025296173057 -Train Accuracy: 0.8121212\n",
      "epoch: 282 - cost: 0.45550907 -MSE: 1.5606031557946969 -Train Accuracy: 0.8424242\n",
      "epoch: 283 - cost: 0.4362337 -MSE: 1.9033938239058295 -Train Accuracy: 0.8181818\n",
      "epoch: 284 - cost: 0.42366722 -MSE: 2.2461928994266236 -Train Accuracy: 0.8545455\n",
      "epoch: 285 - cost: 0.41074875 -MSE: 2.5135922797160606 -Train Accuracy: 0.8242424\n",
      "epoch: 286 - cost: 0.41215333 -MSE: 3.137163881280348 -Train Accuracy: 0.8363636\n",
      "epoch: 287 - cost: 0.45642284 -MSE: 3.1860125826387726 -Train Accuracy: 0.7878788\n",
      "epoch: 288 - cost: 0.6415341 -MSE: 7.061838713071108 -Train Accuracy: 0.6242424\n",
      "epoch: 289 - cost: 0.68718797 -MSE: 2.950376321421543 -Train Accuracy: 0.6787879\n",
      "epoch: 290 - cost: 0.6662098 -MSE: 4.864749931454236 -Train Accuracy: 0.53939396\n",
      "epoch: 291 - cost: 0.50033396 -MSE: 1.6868149859096382 -Train Accuracy: 0.8060606\n",
      "epoch: 292 - cost: 0.44465262 -MSE: 1.9034967990825424 -Train Accuracy: 0.8121212\n",
      "epoch: 293 - cost: 0.42821753 -MSE: 2.798759273244335 -Train Accuracy: 0.8545455\n",
      "epoch: 294 - cost: 0.4188868 -MSE: 2.907840066192049 -Train Accuracy: 0.8121212\n",
      "epoch: 295 - cost: 0.4641042 -MSE: 5.1844799489634665 -Train Accuracy: 0.7878788\n",
      "epoch: 296 - cost: 0.5408015 -MSE: 3.2005811502332673 -Train Accuracy: 0.72727275\n",
      "epoch: 297 - cost: 0.6785828 -MSE: 9.121167236900959 -Train Accuracy: 0.5939394\n",
      "epoch: 298 - cost: 0.50231695 -MSE: 1.603155123288172 -Train Accuracy: 0.75151515\n",
      "epoch: 299 - cost: 0.49397522 -MSE: 2.1872000878573026 -Train Accuracy: 0.7818182\n",
      "epoch: 300 - cost: 0.43322024 -MSE: 2.212039084999261 -Train Accuracy: 0.8121212\n",
      "epoch: 301 - cost: 0.43797612 -MSE: 3.339688352959785 -Train Accuracy: 0.830303\n",
      "epoch: 302 - cost: 0.4358518 -MSE: 3.0181618587356884 -Train Accuracy: 0.8060606\n",
      "epoch: 303 - cost: 0.5261914 -MSE: 6.4748869975293175 -Train Accuracy: 0.7030303\n",
      "epoch: 304 - cost: 0.6321266 -MSE: 3.0240256890167614 -Train Accuracy: 0.7030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 305 - cost: 0.63030887 -MSE: 6.861900766985987 -Train Accuracy: 0.5939394\n",
      "epoch: 306 - cost: 0.43980265 -MSE: 1.6882716615795244 -Train Accuracy: 0.830303\n",
      "epoch: 307 - cost: 0.4116921 -MSE: 2.287819907892054 -Train Accuracy: 0.830303\n",
      "epoch: 308 - cost: 0.39165363 -MSE: 3.0823956185587322 -Train Accuracy: 0.8484849\n",
      "epoch: 309 - cost: 0.37842882 -MSE: 3.473133493166028 -Train Accuracy: 0.8181818\n",
      "epoch: 310 - cost: 0.3690125 -MSE: 4.228184020087419 -Train Accuracy: 0.8424242\n",
      "epoch: 311 - cost: 0.36228845 -MSE: 4.308426349503133 -Train Accuracy: 0.830303\n",
      "epoch: 312 - cost: 0.36659688 -MSE: 5.741784882296979 -Train Accuracy: 0.8484849\n",
      "epoch: 313 - cost: 0.46477374 -MSE: 4.264045968762688 -Train Accuracy: 0.7818182\n",
      "epoch: 314 - cost: 0.92000425 -MSE: 15.619054082346414 -Train Accuracy: 0.58787876\n",
      "epoch: 315 - cost: 0.90002865 -MSE: 3.21154970038703 -Train Accuracy: 0.57575756\n",
      "epoch: 316 - cost: 0.64930934 -MSE: 1.5171080290498746 -Train Accuracy: 0.54545456\n",
      "epoch: 317 - cost: 0.5764147 -MSE: 1.6053379922244566 -Train Accuracy: 0.6242424\n",
      "epoch: 318 - cost: 0.49461994 -MSE: 1.636743426439962 -Train Accuracy: 0.8242424\n",
      "epoch: 319 - cost: 0.42801717 -MSE: 1.9753111055017483 -Train Accuracy: 0.8242424\n",
      "epoch: 320 - cost: 0.39817837 -MSE: 2.7628419120650127 -Train Accuracy: 0.8545455\n",
      "epoch: 321 - cost: 0.3811317 -MSE: 3.245345550473457 -Train Accuracy: 0.8242424\n",
      "epoch: 322 - cost: 0.37526625 -MSE: 4.566673050994816 -Train Accuracy: 0.8484849\n",
      "epoch: 323 - cost: 0.38974744 -MSE: 3.9636570681960146 -Train Accuracy: 0.8121212\n",
      "epoch: 324 - cost: 0.5187156 -MSE: 8.879766358689682 -Train Accuracy: 0.73333335\n",
      "epoch: 325 - cost: 0.8795837 -MSE: 4.003395487319232 -Train Accuracy: 0.630303\n",
      "epoch: 326 - cost: 0.6521859 -MSE: 7.701536889747369 -Train Accuracy: 0.56363636\n",
      "epoch: 327 - cost: 0.4831004 -MSE: 1.5868175951222256 -Train Accuracy: 0.8606061\n",
      "epoch: 328 - cost: 0.42960182 -MSE: 2.1277805854806013 -Train Accuracy: 0.8424242\n",
      "epoch: 329 - cost: 0.39664477 -MSE: 2.8161045719567452 -Train Accuracy: 0.8484849\n",
      "epoch: 330 - cost: 0.3765721 -MSE: 3.359532598511035 -Train Accuracy: 0.8484849\n",
      "epoch: 331 - cost: 0.36573583 -MSE: 4.494391114674123 -Train Accuracy: 0.8666667\n",
      "epoch: 332 - cost: 0.36836395 -MSE: 4.296593989394067 -Train Accuracy: 0.830303\n",
      "epoch: 333 - cost: 0.4177494 -MSE: 7.338726167123742 -Train Accuracy: 0.8181818\n",
      "epoch: 334 - cost: 0.6236798 -MSE: 3.7498953127642247 -Train Accuracy: 0.72727275\n",
      "epoch: 335 - cost: 0.75986075 -MSE: 12.095231104652887 -Train Accuracy: 0.5939394\n",
      "epoch: 336 - cost: 0.55613905 -MSE: 1.6618148575345049 -Train Accuracy: 0.6909091\n",
      "epoch: 337 - cost: 0.48222452 -MSE: 1.4437062222433148 -Train Accuracy: 0.8606061\n",
      "epoch: 338 - cost: 0.4216474 -MSE: 1.8588897429570472 -Train Accuracy: 0.8484849\n",
      "epoch: 339 - cost: 0.39134344 -MSE: 2.3937692407551174 -Train Accuracy: 0.8727273\n",
      "epoch: 340 - cost: 0.36863187 -MSE: 3.1023792927002733 -Train Accuracy: 0.8545455\n",
      "epoch: 341 - cost: 0.35487092 -MSE: 3.759966738064914 -Train Accuracy: 0.8666667\n",
      "epoch: 342 - cost: 0.3475883 -MSE: 4.076428169711454 -Train Accuracy: 0.8545455\n",
      "epoch: 343 - cost: 0.34385654 -MSE: 4.908500502255375 -Train Accuracy: 0.8606061\n",
      "epoch: 344 - cost: 0.36072326 -MSE: 4.505810352302329 -Train Accuracy: 0.8363636\n",
      "epoch: 345 - cost: 0.49783057 -MSE: 8.66705946376485 -Train Accuracy: 0.76969695\n",
      "epoch: 346 - cost: 0.96723354 -MSE: 4.894218859028849 -Train Accuracy: 0.6181818\n",
      "epoch: 347 - cost: 0.70627373 -MSE: 7.900009755578884 -Train Accuracy: 0.5272727\n",
      "epoch: 348 - cost: 0.51392424 -MSE: 1.0857990711538992 -Train Accuracy: 0.8545455\n",
      "epoch: 349 - cost: 0.4449053 -MSE: 1.517936313760596 -Train Accuracy: 0.8545455\n",
      "epoch: 350 - cost: 0.4061956 -MSE: 2.169498088788781 -Train Accuracy: 0.8424242\n",
      "epoch: 351 - cost: 0.37565207 -MSE: 2.9444858923328603 -Train Accuracy: 0.8727273\n",
      "epoch: 352 - cost: 0.35789144 -MSE: 3.512855786789691 -Train Accuracy: 0.8424242\n",
      "epoch: 353 - cost: 0.3587889 -MSE: 4.9057024116516486 -Train Accuracy: 0.8545455\n",
      "epoch: 354 - cost: 0.38647014 -MSE: 4.166130515839721 -Train Accuracy: 0.8181818\n",
      "epoch: 355 - cost: 0.53689975 -MSE: 9.458954126150925 -Train Accuracy: 0.7030303\n",
      "epoch: 356 - cost: 0.8650621 -MSE: 4.028028196354326 -Train Accuracy: 0.630303\n",
      "epoch: 357 - cost: 0.5837149 -MSE: 5.180017287950291 -Train Accuracy: 0.58787876\n",
      "epoch: 358 - cost: 0.47172806 -MSE: 2.6687195581553573 -Train Accuracy: 0.830303\n",
      "epoch: 359 - cost: 0.39487782 -MSE: 2.7163176087360976 -Train Accuracy: 0.8484849\n",
      "epoch: 360 - cost: 0.36454475 -MSE: 3.601769648375479 -Train Accuracy: 0.8545455\n",
      "epoch: 361 - cost: 0.34574962 -MSE: 4.540530566459924 -Train Accuracy: 0.8606061\n",
      "epoch: 362 - cost: 0.33439893 -MSE: 5.056286428851543 -Train Accuracy: 0.8606061\n",
      "epoch: 363 - cost: 0.33003804 -MSE: 6.342637480224893 -Train Accuracy: 0.8666667\n",
      "epoch: 364 - cost: 0.36839423 -MSE: 4.975139320066438 -Train Accuracy: 0.830303\n",
      "epoch: 365 - cost: 0.57355607 -MSE: 12.392590414718976 -Train Accuracy: 0.7090909\n",
      "epoch: 366 - cost: 1.118574 -MSE: 4.72658806478011 -Train Accuracy: 0.56969696\n",
      "epoch: 367 - cost: 0.57382417 -MSE: 2.941074419349726 -Train Accuracy: 0.5939394\n",
      "epoch: 368 - cost: 0.49519163 -MSE: 3.135113361908633 -Train Accuracy: 0.76969695\n",
      "epoch: 369 - cost: 0.41673607 -MSE: 3.1964341113660684 -Train Accuracy: 0.8848485\n",
      "epoch: 370 - cost: 0.36800456 -MSE: 3.9008612810782344 -Train Accuracy: 0.8727273\n",
      "epoch: 371 - cost: 0.34473222 -MSE: 4.627756858762321 -Train Accuracy: 0.8606061\n",
      "epoch: 372 - cost: 0.33217564 -MSE: 5.551020175639465 -Train Accuracy: 0.8606061\n",
      "epoch: 373 - cost: 0.32567453 -MSE: 5.566872950743382 -Train Accuracy: 0.8727273\n",
      "epoch: 374 - cost: 0.32873216 -MSE: 7.22110712467543 -Train Accuracy: 0.8484849\n",
      "epoch: 375 - cost: 0.4169284 -MSE: 4.870968580373949 -Train Accuracy: 0.8\n",
      "epoch: 376 - cost: 0.7427924 -MSE: 15.402368066126796 -Train Accuracy: 0.6363636\n",
      "epoch: 377 - cost: 1.1607733 -MSE: 4.5103542139660195 -Train Accuracy: 0.55151516\n",
      "epoch: 378 - cost: 0.599532 -MSE: 1.4069437968239988 -Train Accuracy: 0.75757575\n",
      "epoch: 379 - cost: 0.5130341 -MSE: 1.5049112194007255 -Train Accuracy: 0.8727273\n",
      "epoch: 380 - cost: 0.4381765 -MSE: 2.0065947362129273 -Train Accuracy: 0.8666667\n",
      "epoch: 381 - cost: 0.38785446 -MSE: 2.695911223969237 -Train Accuracy: 0.8666667\n",
      "epoch: 382 - cost: 0.354569 -MSE: 3.6279884766250117 -Train Accuracy: 0.8666667\n",
      "epoch: 383 - cost: 0.3369705 -MSE: 4.1041264852831985 -Train Accuracy: 0.8666667\n",
      "epoch: 384 - cost: 0.32956713 -MSE: 5.048968065254298 -Train Accuracy: 0.8666667\n",
      "epoch: 385 - cost: 0.34004962 -MSE: 4.682639910425267 -Train Accuracy: 0.8484849\n",
      "epoch: 386 - cost: 0.42357147 -MSE: 8.105480039214326 -Train Accuracy: 0.8121212\n",
      "epoch: 387 - cost: 0.69669336 -MSE: 4.319095599174091 -Train Accuracy: 0.7090909\n",
      "epoch: 388 - cost: 0.6149334 -MSE: 10.17173718503636 -Train Accuracy: 0.6242424\n",
      "epoch: 389 - cost: 0.49964136 -MSE: 1.7237641496551874 -Train Accuracy: 0.72121215\n",
      "epoch: 390 - cost: 0.41526005 -MSE: 2.4061247663918004 -Train Accuracy: 0.8727273\n",
      "epoch: 391 - cost: 0.36630347 -MSE: 3.322138723893287 -Train Accuracy: 0.8727273\n",
      "epoch: 392 - cost: 0.3370572 -MSE: 4.573161408539262 -Train Accuracy: 0.8787879\n",
      "epoch: 393 - cost: 0.32204145 -MSE: 5.14922883090433 -Train Accuracy: 0.8727273\n",
      "epoch: 394 - cost: 0.3179995 -MSE: 6.417836155659996 -Train Accuracy: 0.8727273\n",
      "epoch: 395 - cost: 0.34315878 -MSE: 5.647950600266834 -Train Accuracy: 0.830303\n",
      "epoch: 396 - cost: 0.49978596 -MSE: 12.147341268383782 -Train Accuracy: 0.77575755\n",
      "epoch: 397 - cost: 0.94861597 -MSE: 4.512427959883966 -Train Accuracy: 0.6242424\n",
      "epoch: 398 - cost: 0.51525664 -MSE: 4.647587939202074 -Train Accuracy: 0.6242424\n",
      "epoch: 399 - cost: 0.4358902 -MSE: 3.6449597608667275 -Train Accuracy: 0.8787879\n",
      "epoch: 400 - cost: 0.37018633 -MSE: 4.05314443739456 -Train Accuracy: 0.8909091\n",
      "epoch: 401 - cost: 0.335272 -MSE: 4.98942933321918 -Train Accuracy: 0.8848485\n",
      "epoch: 402 - cost: 0.31913576 -MSE: 5.546753499229323 -Train Accuracy: 0.8727273\n",
      "epoch: 403 - cost: 0.31755608 -MSE: 7.160319572159378 -Train Accuracy: 0.8727273\n",
      "epoch: 404 - cost: 0.36457282 -MSE: 5.326469651134698 -Train Accuracy: 0.830303\n",
      "epoch: 405 - cost: 0.54639155 -MSE: 13.435057517567802 -Train Accuracy: 0.72727275\n",
      "epoch: 406 - cost: 0.95692044 -MSE: 3.995288128107434 -Train Accuracy: 0.58787876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 407 - cost: 0.4805752 -MSE: 3.107511605198489 -Train Accuracy: 0.8242424\n",
      "epoch: 408 - cost: 0.41091213 -MSE: 3.705791708753767 -Train Accuracy: 0.8848485\n",
      "epoch: 409 - cost: 0.35927835 -MSE: 4.099189290866015 -Train Accuracy: 0.8909091\n",
      "epoch: 410 - cost: 0.33014864 -MSE: 4.754500975502589 -Train Accuracy: 0.8727273\n",
      "epoch: 411 - cost: 0.31826967 -MSE: 6.041371697931203 -Train Accuracy: 0.8787879\n",
      "epoch: 412 - cost: 0.3221963 -MSE: 5.533761886292139 -Train Accuracy: 0.8484849\n",
      "epoch: 413 - cost: 0.37667263 -MSE: 9.092322920215835 -Train Accuracy: 0.8363636\n",
      "epoch: 414 - cost: 0.59111685 -MSE: 4.427254954158365 -Train Accuracy: 0.73939395\n",
      "epoch: 415 - cost: 0.58608973 -MSE: 12.772619966660656 -Train Accuracy: 0.6848485\n",
      "epoch: 416 - cost: 0.6619373 -MSE: 2.5276919130681534 -Train Accuracy: 0.630303\n",
      "epoch: 417 - cost: 0.4488688 -MSE: 2.0406886180315773 -Train Accuracy: 0.8727273\n",
      "epoch: 418 - cost: 0.38193688 -MSE: 3.1884311352382584 -Train Accuracy: 0.8484849\n",
      "epoch: 419 - cost: 0.338699 -MSE: 4.35086073117731 -Train Accuracy: 0.8787879\n",
      "epoch: 420 - cost: 0.31779683 -MSE: 5.80824333391929 -Train Accuracy: 0.8969697\n",
      "epoch: 421 - cost: 0.31091493 -MSE: 5.768551320773942 -Train Accuracy: 0.8666667\n",
      "epoch: 422 - cost: 0.32138178 -MSE: 8.114123298047486 -Train Accuracy: 0.8666667\n",
      "epoch: 423 - cost: 0.42101666 -MSE: 5.006744703450011 -Train Accuracy: 0.7939394\n",
      "epoch: 424 - cost: 0.5759169 -MSE: 13.614477791100356 -Train Accuracy: 0.6969697\n",
      "epoch: 425 - cost: 0.85371065 -MSE: 3.5342164839913126 -Train Accuracy: 0.6060606\n",
      "epoch: 426 - cost: 0.47965232 -MSE: 2.3738790806329417 -Train Accuracy: 0.8727273\n",
      "epoch: 427 - cost: 0.40136796 -MSE: 3.1224184035182314 -Train Accuracy: 0.8848485\n",
      "epoch: 428 - cost: 0.3471965 -MSE: 3.9801790144830798 -Train Accuracy: 0.9030303\n",
      "epoch: 429 - cost: 0.31734934 -MSE: 4.937593915042834 -Train Accuracy: 0.8969697\n",
      "epoch: 430 - cost: 0.3042871 -MSE: 5.685091446053316 -Train Accuracy: 0.8848485\n",
      "epoch: 431 - cost: 0.29725924 -MSE: 5.834593580854157 -Train Accuracy: 0.8969697\n",
      "epoch: 432 - cost: 0.29485378 -MSE: 6.828524799206881 -Train Accuracy: 0.8727273\n",
      "epoch: 433 - cost: 0.30981657 -MSE: 6.211122726006062 -Train Accuracy: 0.8484849\n",
      "epoch: 434 - cost: 0.41401958 -MSE: 10.66649237904046 -Train Accuracy: 0.8121212\n",
      "epoch: 435 - cost: 0.8070946 -MSE: 4.676484562668227 -Train Accuracy: 0.6606061\n",
      "epoch: 436 - cost: 0.5408087 -MSE: 9.146830826256695 -Train Accuracy: 0.6424242\n",
      "epoch: 437 - cost: 0.43686256 -MSE: 1.8162441707884982 -Train Accuracy: 0.74545455\n",
      "epoch: 438 - cost: 0.36633995 -MSE: 3.2111261564170754 -Train Accuracy: 0.8484849\n",
      "epoch: 439 - cost: 0.32569614 -MSE: 4.178795277532124 -Train Accuracy: 0.8666667\n",
      "epoch: 440 - cost: 0.3036706 -MSE: 5.951803257280666 -Train Accuracy: 0.8969697\n",
      "epoch: 441 - cost: 0.29400924 -MSE: 6.225471699760173 -Train Accuracy: 0.8909091\n",
      "epoch: 442 - cost: 0.30548832 -MSE: 8.707165449225402 -Train Accuracy: 0.8848485\n",
      "epoch: 443 - cost: 0.39852577 -MSE: 5.3744852270731345 -Train Accuracy: 0.8060606\n",
      "epoch: 444 - cost: 0.58875906 -MSE: 14.712184492458661 -Train Accuracy: 0.7151515\n",
      "epoch: 445 - cost: 0.9073698 -MSE: 3.6557647890098663 -Train Accuracy: 0.58787876\n",
      "epoch: 446 - cost: 0.49266717 -MSE: 2.0560639263356686 -Train Accuracy: 0.8666667\n",
      "epoch: 447 - cost: 0.4105519 -MSE: 2.971226120181482 -Train Accuracy: 0.8787879\n",
      "epoch: 448 - cost: 0.34650275 -MSE: 3.8112474722359897 -Train Accuracy: 0.8969697\n",
      "epoch: 449 - cost: 0.3111091 -MSE: 4.6835654583801105 -Train Accuracy: 0.8848485\n",
      "epoch: 450 - cost: 0.29613695 -MSE: 5.562523104805488 -Train Accuracy: 0.8848485\n",
      "epoch: 451 - cost: 0.2914774 -MSE: 5.528110718060172 -Train Accuracy: 0.8969697\n",
      "epoch: 452 - cost: 0.30177963 -MSE: 7.03504558994467 -Train Accuracy: 0.8727273\n",
      "epoch: 453 - cost: 0.35668558 -MSE: 5.549751813924304 -Train Accuracy: 0.8242424\n",
      "epoch: 454 - cost: 0.5745382 -MSE: 13.448846229584314 -Train Accuracy: 0.7151515\n",
      "epoch: 455 - cost: 0.9994814 -MSE: 4.3393318372450755 -Train Accuracy: 0.58787876\n",
      "epoch: 456 - cost: 0.48542124 -MSE: 2.37715390124231 -Train Accuracy: 0.8727273\n",
      "epoch: 457 - cost: 0.40616465 -MSE: 3.52009202286739 -Train Accuracy: 0.9030303\n",
      "epoch: 458 - cost: 0.3442709 -MSE: 4.218000706326957 -Train Accuracy: 0.8909091\n",
      "epoch: 459 - cost: 0.31056795 -MSE: 4.798598748409042 -Train Accuracy: 0.8848485\n",
      "epoch: 460 - cost: 0.29437256 -MSE: 5.714797182130009 -Train Accuracy: 0.9030303\n",
      "epoch: 461 - cost: 0.29089087 -MSE: 5.577751034782521 -Train Accuracy: 0.8909091\n",
      "epoch: 462 - cost: 0.30945042 -MSE: 7.245224796539971 -Train Accuracy: 0.8727273\n",
      "epoch: 463 - cost: 0.3930545 -MSE: 5.210491339483879 -Train Accuracy: 0.8181818\n",
      "epoch: 464 - cost: 0.6081562 -MSE: 14.121961975125043 -Train Accuracy: 0.6727273\n",
      "epoch: 465 - cost: 0.93253314 -MSE: 4.078582617338857 -Train Accuracy: 0.58787876\n",
      "epoch: 466 - cost: 0.46985394 -MSE: 2.3391863717854373 -Train Accuracy: 0.8666667\n",
      "epoch: 467 - cost: 0.39112294 -MSE: 3.483041861079878 -Train Accuracy: 0.8727273\n",
      "epoch: 468 - cost: 0.33386555 -MSE: 5.045532683594711 -Train Accuracy: 0.8909091\n",
      "epoch: 469 - cost: 0.30464852 -MSE: 5.511949931342291 -Train Accuracy: 0.8909091\n",
      "epoch: 470 - cost: 0.29159304 -MSE: 6.5489194035985445 -Train Accuracy: 0.9030303\n",
      "epoch: 471 - cost: 0.2903962 -MSE: 6.091283300879088 -Train Accuracy: 0.8787879\n",
      "epoch: 472 - cost: 0.31491223 -MSE: 8.333160722936467 -Train Accuracy: 0.8666667\n",
      "epoch: 473 - cost: 0.40435255 -MSE: 5.541720489598372 -Train Accuracy: 0.8121212\n",
      "epoch: 474 - cost: 0.62115306 -MSE: 15.675990701004888 -Train Accuracy: 0.6666667\n",
      "epoch: 475 - cost: 0.9266387 -MSE: 4.1007699017990165 -Train Accuracy: 0.58787876\n",
      "epoch: 476 - cost: 0.47712073 -MSE: 1.9528637511492604 -Train Accuracy: 0.8545455\n",
      "epoch: 477 - cost: 0.3971032 -MSE: 3.04764006751478 -Train Accuracy: 0.8666667\n",
      "epoch: 478 - cost: 0.33466038 -MSE: 4.595550777102149 -Train Accuracy: 0.8909091\n",
      "epoch: 479 - cost: 0.30228862 -MSE: 5.247573577652556 -Train Accuracy: 0.8909091\n",
      "epoch: 480 - cost: 0.2869582 -MSE: 6.035525063394029 -Train Accuracy: 0.8969697\n",
      "epoch: 481 - cost: 0.28049073 -MSE: 5.9912655071280465 -Train Accuracy: 0.8909091\n",
      "epoch: 482 - cost: 0.28487983 -MSE: 7.117830121359064 -Train Accuracy: 0.8848485\n",
      "epoch: 483 - cost: 0.3399726 -MSE: 5.529900465167879 -Train Accuracy: 0.830303\n",
      "epoch: 484 - cost: 0.5307077 -MSE: 12.199680607591409 -Train Accuracy: 0.72121215\n",
      "epoch: 485 - cost: 0.84424603 -MSE: 4.405600775634028 -Train Accuracy: 0.6484848\n",
      "epoch: 486 - cost: 0.42500257 -MSE: 5.427737184475208 -Train Accuracy: 0.8727273\n",
      "epoch: 487 - cost: 0.35452166 -MSE: 4.063168680869303 -Train Accuracy: 0.8969697\n",
      "epoch: 488 - cost: 0.30814162 -MSE: 5.098189450883831 -Train Accuracy: 0.8909091\n",
      "epoch: 489 - cost: 0.2862043 -MSE: 5.821042568516437 -Train Accuracy: 0.8787879\n",
      "epoch: 490 - cost: 0.27502155 -MSE: 6.5905198352604275 -Train Accuracy: 0.9030303\n",
      "epoch: 491 - cost: 0.27077276 -MSE: 6.447491976482486 -Train Accuracy: 0.8909091\n",
      "epoch: 492 - cost: 0.27413195 -MSE: 7.422562361694389 -Train Accuracy: 0.9030303\n",
      "epoch: 493 - cost: 0.3087375 -MSE: 6.13169014527371 -Train Accuracy: 0.8424242\n",
      "epoch: 494 - cost: 0.4729475 -MSE: 12.143181427875236 -Train Accuracy: 0.77575755\n",
      "epoch: 495 - cost: 0.8562124 -MSE: 4.603931949837941 -Train Accuracy: 0.6484848\n",
      "epoch: 496 - cost: 0.43116876 -MSE: 6.447761007542594 -Train Accuracy: 0.8242424\n",
      "epoch: 497 - cost: 0.350684 -MSE: 4.359048936586332 -Train Accuracy: 0.8787879\n",
      "epoch: 498 - cost: 0.30442798 -MSE: 5.245987011896472 -Train Accuracy: 0.8909091\n",
      "epoch: 499 - cost: 0.2815005 -MSE: 6.17532294137997 -Train Accuracy: 0.8848485\n",
      "epoch: 500 - cost: 0.2693552 -MSE: 6.9978387335920536 -Train Accuracy: 0.8969697\n",
      "epoch: 501 - cost: 0.2629777 -MSE: 7.306968170408536 -Train Accuracy: 0.8909091\n",
      "epoch: 502 - cost: 0.2607571 -MSE: 8.646169282446511 -Train Accuracy: 0.90909094\n",
      "epoch: 503 - cost: 0.29151013 -MSE: 7.261770994923599 -Train Accuracy: 0.8545455\n",
      "epoch: 504 - cost: 0.44890076 -MSE: 14.03344145446808 -Train Accuracy: 0.7939394\n",
      "epoch: 505 - cost: 0.9613624 -MSE: 4.903228812042828 -Train Accuracy: 0.630303\n",
      "epoch: 506 - cost: 0.41825807 -MSE: 5.2700596691289565 -Train Accuracy: 0.8666667\n",
      "epoch: 507 - cost: 0.35000867 -MSE: 4.033175521849638 -Train Accuracy: 0.8909091\n",
      "epoch: 508 - cost: 0.30235946 -MSE: 5.054604151200751 -Train Accuracy: 0.8909091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 509 - cost: 0.2782959 -MSE: 5.666258099260359 -Train Accuracy: 0.8969697\n",
      "epoch: 510 - cost: 0.26515344 -MSE: 6.314662264078138 -Train Accuracy: 0.90909094\n",
      "epoch: 511 - cost: 0.25785333 -MSE: 6.596983875103586 -Train Accuracy: 0.90909094\n",
      "epoch: 512 - cost: 0.25363904 -MSE: 6.586011681383866 -Train Accuracy: 0.9030303\n",
      "epoch: 513 - cost: 0.2551486 -MSE: 7.167715881484955 -Train Accuracy: 0.90909094\n",
      "epoch: 514 - cost: 0.28941754 -MSE: 5.962236475223845 -Train Accuracy: 0.8545455\n",
      "epoch: 515 - cost: 0.49557912 -MSE: 11.452563161898762 -Train Accuracy: 0.75757575\n",
      "epoch: 516 - cost: 0.95619607 -MSE: 4.887647350189787 -Train Accuracy: 0.6363636\n",
      "epoch: 517 - cost: 0.41549465 -MSE: 6.1490573150312215 -Train Accuracy: 0.8484849\n",
      "epoch: 518 - cost: 0.35086197 -MSE: 4.300564276927018 -Train Accuracy: 0.8848485\n",
      "epoch: 519 - cost: 0.3000491 -MSE: 5.225957964630875 -Train Accuracy: 0.8969697\n",
      "epoch: 520 - cost: 0.27392238 -MSE: 6.152493836271449 -Train Accuracy: 0.8969697\n",
      "epoch: 521 - cost: 0.26108223 -MSE: 6.547447991419481 -Train Accuracy: 0.90909094\n",
      "epoch: 522 - cost: 0.25428924 -MSE: 6.5877207541253116 -Train Accuracy: 0.8969697\n",
      "epoch: 523 - cost: 0.25200966 -MSE: 7.484334013449846 -Train Accuracy: 0.90909094\n",
      "epoch: 524 - cost: 0.2734428 -MSE: 6.649048878602568 -Train Accuracy: 0.8787879\n",
      "epoch: 525 - cost: 0.39460745 -MSE: 11.037708469626793 -Train Accuracy: 0.8060606\n",
      "epoch: 526 - cost: 0.84414786 -MSE: 4.948253305982417 -Train Accuracy: 0.6666667\n",
      "epoch: 527 - cost: 0.43821388 -MSE: 8.418228252359308 -Train Accuracy: 0.76363635\n",
      "epoch: 528 - cost: 0.37546352 -MSE: 2.740140522199207 -Train Accuracy: 0.8060606\n",
      "epoch: 529 - cost: 0.30652094 -MSE: 5.287430928946365 -Train Accuracy: 0.8909091\n",
      "epoch: 530 - cost: 0.2692936 -MSE: 7.287435988089323 -Train Accuracy: 0.90909094\n",
      "epoch: 531 - cost: 0.25086057 -MSE: 7.915464711408791 -Train Accuracy: 0.90909094\n",
      "epoch: 532 - cost: 0.24268438 -MSE: 10.116894529990166 -Train Accuracy: 0.91515154\n",
      "epoch: 533 - cost: 0.24314198 -MSE: 8.891545015799553 -Train Accuracy: 0.90909094\n",
      "epoch: 534 - cost: 0.3175778 -MSE: 15.544599579889526 -Train Accuracy: 0.8363636\n",
      "epoch: 535 - cost: 0.75593156 -MSE: 5.4214184047935206 -Train Accuracy: 0.7030303\n",
      "epoch: 536 - cost: 0.55739427 -MSE: 16.132834972513223 -Train Accuracy: 0.72121215\n",
      "epoch: 537 - cost: 0.58718866 -MSE: 1.981672735575731 -Train Accuracy: 0.6242424\n",
      "epoch: 538 - cost: 0.4281518 -MSE: 1.8932055375773482 -Train Accuracy: 0.76969695\n",
      "epoch: 539 - cost: 0.34484634 -MSE: 3.5007815300479725 -Train Accuracy: 0.830303\n",
      "epoch: 540 - cost: 0.29633415 -MSE: 4.983153152768613 -Train Accuracy: 0.8969697\n",
      "epoch: 541 - cost: 0.26715806 -MSE: 6.193251568687553 -Train Accuracy: 0.8969697\n",
      "epoch: 542 - cost: 0.25218344 -MSE: 6.598488859996789 -Train Accuracy: 0.91515154\n",
      "epoch: 543 - cost: 0.24402031 -MSE: 6.727616549803708 -Train Accuracy: 0.90909094\n",
      "epoch: 544 - cost: 0.24044612 -MSE: 7.280032224460722 -Train Accuracy: 0.90909094\n",
      "epoch: 545 - cost: 0.2412007 -MSE: 7.1155376262910135 -Train Accuracy: 0.9030303\n",
      "epoch: 546 - cost: 0.27127817 -MSE: 8.84169598586509 -Train Accuracy: 0.8969697\n",
      "epoch: 547 - cost: 0.4523769 -MSE: 5.978875528304765 -Train Accuracy: 0.7939394\n",
      "epoch: 548 - cost: 0.70671934 -MSE: 16.208683373078266 -Train Accuracy: 0.6606061\n",
      "epoch: 549 - cost: 1.00169 -MSE: 3.7486756492362168 -Train Accuracy: 0.57575756\n",
      "epoch: 550 - cost: 0.5476117 -MSE: 0.9344213206868601 -Train Accuracy: 0.77575755\n",
      "epoch: 551 - cost: 0.45914662 -MSE: 1.476503389370198 -Train Accuracy: 0.8060606\n",
      "epoch: 552 - cost: 0.3732011 -MSE: 2.4678823158078425 -Train Accuracy: 0.830303\n",
      "epoch: 553 - cost: 0.31247005 -MSE: 3.518351887685336 -Train Accuracy: 0.9030303\n",
      "epoch: 554 - cost: 0.2720978 -MSE: 4.724317737737829 -Train Accuracy: 0.90909094\n",
      "epoch: 555 - cost: 0.25398612 -MSE: 5.344884751229561 -Train Accuracy: 0.90909094\n",
      "epoch: 556 - cost: 0.24531099 -MSE: 6.085728439032583 -Train Accuracy: 0.90909094\n",
      "epoch: 557 - cost: 0.24606328 -MSE: 5.836851890405861 -Train Accuracy: 0.9030303\n",
      "epoch: 558 - cost: 0.27449396 -MSE: 7.365086238530948 -Train Accuracy: 0.9030303\n",
      "epoch: 559 - cost: 0.41018414 -MSE: 5.380113568195846 -Train Accuracy: 0.8121212\n",
      "epoch: 560 - cost: 0.56478155 -MSE: 11.209610375147003 -Train Accuracy: 0.6969697\n",
      "epoch: 561 - cost: 0.7970162 -MSE: 3.884084271918208 -Train Accuracy: 0.630303\n",
      "epoch: 562 - cost: 0.41918653 -MSE: 3.12220328269483 -Train Accuracy: 0.8909091\n",
      "epoch: 563 - cost: 0.335776 -MSE: 3.9758755178021348 -Train Accuracy: 0.8969697\n",
      "epoch: 564 - cost: 0.27957743 -MSE: 4.8185525947970005 -Train Accuracy: 0.9030303\n",
      "epoch: 565 - cost: 0.25654826 -MSE: 6.136445981158584 -Train Accuracy: 0.91515154\n",
      "epoch: 566 - cost: 0.24379773 -MSE: 6.150899021703592 -Train Accuracy: 0.9030303\n",
      "epoch: 567 - cost: 0.23658748 -MSE: 6.625962696228382 -Train Accuracy: 0.91515154\n",
      "epoch: 568 - cost: 0.23383003 -MSE: 6.489561627108326 -Train Accuracy: 0.9030303\n",
      "epoch: 569 - cost: 0.24617864 -MSE: 7.434692755010921 -Train Accuracy: 0.92121214\n",
      "epoch: 570 - cost: 0.31285036 -MSE: 5.821866125510168 -Train Accuracy: 0.830303\n",
      "epoch: 571 - cost: 0.5552135 -MSE: 12.38637598138608 -Train Accuracy: 0.7090909\n",
      "epoch: 572 - cost: 0.9398394 -MSE: 4.6666257079689 -Train Accuracy: 0.6181818\n",
      "epoch: 573 - cost: 0.42551148 -MSE: 3.906469038545719 -Train Accuracy: 0.8666667\n",
      "epoch: 574 - cost: 0.3542842 -MSE: 4.708309462584906 -Train Accuracy: 0.91515154\n",
      "epoch: 575 - cost: 0.29166082 -MSE: 4.678272528535589 -Train Accuracy: 0.90909094\n",
      "epoch: 576 - cost: 0.25939846 -MSE: 5.740903468129224 -Train Accuracy: 0.9030303\n",
      "epoch: 577 - cost: 0.24388474 -MSE: 6.376532906463958 -Train Accuracy: 0.91515154\n",
      "epoch: 578 - cost: 0.23525326 -MSE: 6.430785684186416 -Train Accuracy: 0.91515154\n",
      "epoch: 579 - cost: 0.22967032 -MSE: 6.8889984308523 -Train Accuracy: 0.91515154\n",
      "epoch: 580 - cost: 0.2310929 -MSE: 6.623821556199443 -Train Accuracy: 0.90909094\n",
      "epoch: 581 - cost: 0.26868516 -MSE: 8.40808158148143 -Train Accuracy: 0.8848485\n",
      "epoch: 582 - cost: 0.42932817 -MSE: 6.147274268488069 -Train Accuracy: 0.8121212\n",
      "epoch: 583 - cost: 0.6582154 -MSE: 14.045237332327257 -Train Accuracy: 0.6666667\n",
      "epoch: 584 - cost: 0.9587129 -MSE: 4.247862632816655 -Train Accuracy: 0.5939394\n",
      "epoch: 585 - cost: 0.47376996 -MSE: 1.625088425982717 -Train Accuracy: 0.8242424\n",
      "epoch: 586 - cost: 0.38108534 -MSE: 2.654660188977731 -Train Accuracy: 0.830303\n",
      "epoch: 587 - cost: 0.30830985 -MSE: 3.9810146983977988 -Train Accuracy: 0.90909094\n",
      "epoch: 588 - cost: 0.26452544 -MSE: 5.466392905364189 -Train Accuracy: 0.90909094\n",
      "epoch: 589 - cost: 0.24537395 -MSE: 6.043091029556659 -Train Accuracy: 0.90909094\n",
      "epoch: 590 - cost: 0.23449132 -MSE: 6.729784563124197 -Train Accuracy: 0.91515154\n",
      "epoch: 591 - cost: 0.22703242 -MSE: 6.910809354985038 -Train Accuracy: 0.91515154\n",
      "epoch: 592 - cost: 0.22274794 -MSE: 7.323137206026488 -Train Accuracy: 0.91515154\n",
      "epoch: 593 - cost: 0.2236731 -MSE: 6.965085144625009 -Train Accuracy: 0.91515154\n",
      "epoch: 594 - cost: 0.2518305 -MSE: 8.514543897440934 -Train Accuracy: 0.91515154\n",
      "epoch: 595 - cost: 0.3908023 -MSE: 6.191535982417742 -Train Accuracy: 0.8121212\n",
      "epoch: 596 - cost: 0.6970428 -MSE: 15.059388235117153 -Train Accuracy: 0.6606061\n",
      "epoch: 597 - cost: 1.0531597 -MSE: 4.845208216759891 -Train Accuracy: 0.58181816\n",
      "epoch: 598 - cost: 0.47828937 -MSE: 1.874796834284559 -Train Accuracy: 0.830303\n",
      "epoch: 599 - cost: 0.38874966 -MSE: 2.9364981268458386 -Train Accuracy: 0.8545455\n",
      "epoch: 600 - cost: 0.31413516 -MSE: 4.237532736789158 -Train Accuracy: 0.92121214\n",
      "epoch: 601 - cost: 0.26827154 -MSE: 5.81479705363847 -Train Accuracy: 0.90909094\n",
      "epoch: 602 - cost: 0.24663289 -MSE: 6.503962996310825 -Train Accuracy: 0.90909094\n",
      "epoch: 603 - cost: 0.23478526 -MSE: 7.201356901198862 -Train Accuracy: 0.91515154\n",
      "epoch: 604 - cost: 0.22622801 -MSE: 7.389841225905883 -Train Accuracy: 0.91515154\n",
      "epoch: 605 - cost: 0.22041425 -MSE: 7.635561805732274 -Train Accuracy: 0.91515154\n",
      "epoch: 606 - cost: 0.21675503 -MSE: 7.549154550484459 -Train Accuracy: 0.91515154\n",
      "epoch: 607 - cost: 0.21485464 -MSE: 7.914770922174467 -Train Accuracy: 0.91515154\n",
      "epoch: 608 - cost: 0.22094898 -MSE: 7.296686233103888 -Train Accuracy: 0.92121214\n",
      "epoch: 609 - cost: 0.27126992 -MSE: 9.248526922363535 -Train Accuracy: 0.8848485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 610 - cost: 0.49649867 -MSE: 6.701759980519417 -Train Accuracy: 0.7939394\n",
      "epoch: 611 - cost: 0.66566664 -MSE: 14.181850034213543 -Train Accuracy: 0.6484848\n",
      "epoch: 612 - cost: 0.8353054 -MSE: 3.915705922251113 -Train Accuracy: 0.6\n",
      "epoch: 613 - cost: 0.4387486 -MSE: 2.212329561313485 -Train Accuracy: 0.8606061\n",
      "epoch: 614 - cost: 0.34366897 -MSE: 3.477887992383405 -Train Accuracy: 0.8606061\n",
      "epoch: 615 - cost: 0.28160965 -MSE: 4.984918083369337 -Train Accuracy: 0.92121214\n",
      "epoch: 616 - cost: 0.24928354 -MSE: 6.603041021336962 -Train Accuracy: 0.91515154\n",
      "epoch: 617 - cost: 0.23657499 -MSE: 6.6523375524587145 -Train Accuracy: 0.91515154\n",
      "epoch: 618 - cost: 0.22775172 -MSE: 7.773052355294586 -Train Accuracy: 0.90909094\n",
      "epoch: 619 - cost: 0.22406518 -MSE: 7.426564203603083 -Train Accuracy: 0.92121214\n",
      "epoch: 620 - cost: 0.2298566 -MSE: 8.762242346110478 -Train Accuracy: 0.93333334\n",
      "epoch: 621 - cost: 0.26698557 -MSE: 7.190994039320778 -Train Accuracy: 0.8666667\n",
      "epoch: 622 - cost: 0.43320516 -MSE: 12.65168637665105 -Train Accuracy: 0.77575755\n",
      "epoch: 623 - cost: 0.79233605 -MSE: 6.003141493091635 -Train Accuracy: 0.6848485\n",
      "epoch: 624 - cost: 0.39445597 -MSE: 7.130742502508835 -Train Accuracy: 0.830303\n",
      "epoch: 625 - cost: 0.3024893 -MSE: 4.739448776415514 -Train Accuracy: 0.8909091\n",
      "epoch: 626 - cost: 0.25182042 -MSE: 5.724539084424869 -Train Accuracy: 0.91515154\n",
      "epoch: 627 - cost: 0.22993004 -MSE: 6.939506805561202 -Train Accuracy: 0.92121214\n",
      "epoch: 628 - cost: 0.21862784 -MSE: 7.529850126146107 -Train Accuracy: 0.92121214\n",
      "epoch: 629 - cost: 0.21076792 -MSE: 8.267296261338165 -Train Accuracy: 0.92121214\n",
      "epoch: 630 - cost: 0.20484602 -MSE: 9.1670369025286 -Train Accuracy: 0.92727274\n",
      "epoch: 631 - cost: 0.20328397 -MSE: 9.136101651046866 -Train Accuracy: 0.91515154\n",
      "epoch: 632 - cost: 0.22131465 -MSE: 11.604034009641591 -Train Accuracy: 0.93333334\n",
      "epoch: 633 - cost: 0.34471115 -MSE: 7.681555771084705 -Train Accuracy: 0.8242424\n",
      "epoch: 634 - cost: 0.6094407 -MSE: 17.03420692199459 -Train Accuracy: 0.7090909\n",
      "epoch: 635 - cost: 1.1158202 -MSE: 5.807401074031549 -Train Accuracy: 0.58181816\n",
      "epoch: 636 - cost: 0.48825148 -MSE: 1.653851652536759 -Train Accuracy: 0.8424242\n",
      "epoch: 637 - cost: 0.39589903 -MSE: 2.6280258110543424 -Train Accuracy: 0.8848485\n",
      "epoch: 638 - cost: 0.30595732 -MSE: 3.895627225563133 -Train Accuracy: 0.92121214\n",
      "epoch: 639 - cost: 0.25618646 -MSE: 4.887947834944071 -Train Accuracy: 0.91515154\n",
      "epoch: 640 - cost: 0.23387444 -MSE: 5.724164966915837 -Train Accuracy: 0.91515154\n",
      "epoch: 641 - cost: 0.2211505 -MSE: 6.114058171335319 -Train Accuracy: 0.92121214\n",
      "epoch: 642 - cost: 0.21279508 -MSE: 6.69384390746419 -Train Accuracy: 0.91515154\n",
      "epoch: 643 - cost: 0.20798911 -MSE: 6.876021373238459 -Train Accuracy: 0.92121214\n",
      "epoch: 644 - cost: 0.20652933 -MSE: 7.4686037217416406 -Train Accuracy: 0.93333334\n",
      "epoch: 645 - cost: 0.21940888 -MSE: 7.027433000729873 -Train Accuracy: 0.92727274\n",
      "epoch: 646 - cost: 0.30999762 -MSE: 9.511676795062023 -Train Accuracy: 0.8606061\n",
      "epoch: 647 - cost: 0.64998823 -MSE: 7.269601571571635 -Train Accuracy: 0.75151515\n",
      "epoch: 648 - cost: 0.5417414 -MSE: 11.57252135553715 -Train Accuracy: 0.6969697\n",
      "epoch: 649 - cost: 0.5352142 -MSE: 2.7881817569582568 -Train Accuracy: 0.6727273\n",
      "epoch: 650 - cost: 0.33134454 -MSE: 3.920866382306347 -Train Accuracy: 0.8787879\n",
      "epoch: 651 - cost: 0.2657185 -MSE: 5.29607828840364 -Train Accuracy: 0.91515154\n",
      "epoch: 652 - cost: 0.23362371 -MSE: 6.740547499418969 -Train Accuracy: 0.92121214\n",
      "epoch: 653 - cost: 0.21761988 -MSE: 7.264478716087992 -Train Accuracy: 0.92121214\n",
      "epoch: 654 - cost: 0.20868665 -MSE: 7.926394939500538 -Train Accuracy: 0.92727274\n",
      "epoch: 655 - cost: 0.2026579 -MSE: 8.162644901054236 -Train Accuracy: 0.92727274\n",
      "epoch: 656 - cost: 0.19788621 -MSE: 8.608533248647406 -Train Accuracy: 0.92727274\n",
      "epoch: 657 - cost: 0.19328696 -MSE: 9.281114424174854 -Train Accuracy: 0.93333334\n",
      "epoch: 658 - cost: 0.19128405 -MSE: 9.540943288385261 -Train Accuracy: 0.92121214\n",
      "epoch: 659 - cost: 0.20096542 -MSE: 11.206634304659438 -Train Accuracy: 0.93939394\n",
      "epoch: 660 - cost: 0.26999074 -MSE: 8.810653520028065 -Train Accuracy: 0.8545455\n",
      "epoch: 661 - cost: 0.6311325 -MSE: 19.108114053418046 -Train Accuracy: 0.7090909\n",
      "epoch: 662 - cost: 1.3657535 -MSE: 7.629190953735789 -Train Accuracy: 0.57575756\n",
      "epoch: 663 - cost: 0.5075856 -MSE: 1.7838373037263917 -Train Accuracy: 0.8121212\n",
      "epoch: 664 - cost: 0.42766705 -MSE: 2.762256795311617 -Train Accuracy: 0.8909091\n",
      "epoch: 665 - cost: 0.34537148 -MSE: 4.250412378681041 -Train Accuracy: 0.91515154\n",
      "epoch: 666 - cost: 0.28015935 -MSE: 5.068030368642872 -Train Accuracy: 0.90909094\n",
      "epoch: 667 - cost: 0.23946702 -MSE: 5.44903363530268 -Train Accuracy: 0.92121214\n",
      "epoch: 668 - cost: 0.22007386 -MSE: 6.476127187352217 -Train Accuracy: 0.92121214\n",
      "epoch: 669 - cost: 0.21004339 -MSE: 6.436136136270033 -Train Accuracy: 0.92121214\n",
      "epoch: 670 - cost: 0.2059682 -MSE: 7.355722029936999 -Train Accuracy: 0.94545454\n",
      "epoch: 671 - cost: 0.21098319 -MSE: 6.74175744576345 -Train Accuracy: 0.92727274\n",
      "epoch: 672 - cost: 0.24898957 -MSE: 8.742046410029868 -Train Accuracy: 0.8909091\n",
      "epoch: 673 - cost: 0.41368717 -MSE: 6.483748458852311 -Train Accuracy: 0.8242424\n",
      "epoch: 674 - cost: 0.50943166 -MSE: 11.70774384068208 -Train Accuracy: 0.7151515\n",
      "epoch: 675 - cost: 0.7025367 -MSE: 3.9989514405979985 -Train Accuracy: 0.6666667\n",
      "epoch: 676 - cost: 0.32408965 -MSE: 4.921917741456069 -Train Accuracy: 0.90909094\n",
      "epoch: 677 - cost: 0.256327 -MSE: 5.480817344980546 -Train Accuracy: 0.92121214\n",
      "epoch: 678 - cost: 0.22487795 -MSE: 6.359664769996579 -Train Accuracy: 0.91515154\n",
      "epoch: 679 - cost: 0.2099466 -MSE: 6.93103339372719 -Train Accuracy: 0.92727274\n",
      "epoch: 680 - cost: 0.20145315 -MSE: 7.210497455661733 -Train Accuracy: 0.92121214\n",
      "epoch: 681 - cost: 0.19639093 -MSE: 7.597732465973016 -Train Accuracy: 0.93939394\n",
      "epoch: 682 - cost: 0.19232939 -MSE: 7.684953299694515 -Train Accuracy: 0.92727274\n",
      "epoch: 683 - cost: 0.18893993 -MSE: 8.02683982173593 -Train Accuracy: 0.93939394\n",
      "epoch: 684 - cost: 0.1863527 -MSE: 8.261562356247044 -Train Accuracy: 0.93939394\n",
      "epoch: 685 - cost: 0.18422441 -MSE: 8.657807617062689 -Train Accuracy: 0.93939394\n",
      "epoch: 686 - cost: 0.1858203 -MSE: 8.515297785039795 -Train Accuracy: 0.92121214\n",
      "epoch: 687 - cost: 0.20062022 -MSE: 9.76078733509888 -Train Accuracy: 0.93939394\n",
      "epoch: 688 - cost: 0.27409312 -MSE: 7.904223989178449 -Train Accuracy: 0.8545455\n",
      "epoch: 689 - cost: 0.6007252 -MSE: 15.245820654664104 -Train Accuracy: 0.7030303\n",
      "epoch: 690 - cost: 1.2057017 -MSE: 7.312526347474024 -Train Accuracy: 0.6\n",
      "epoch: 691 - cost: 0.41340202 -MSE: 3.7485354244225215 -Train Accuracy: 0.9030303\n",
      "epoch: 692 - cost: 0.34437224 -MSE: 5.2081551431562945 -Train Accuracy: 0.91515154\n",
      "epoch: 693 - cost: 0.28244302 -MSE: 5.896941806164433 -Train Accuracy: 0.92121214\n",
      "epoch: 694 - cost: 0.23226757 -MSE: 6.141994729309862 -Train Accuracy: 0.92121214\n",
      "epoch: 695 - cost: 0.20840873 -MSE: 7.222389868663619 -Train Accuracy: 0.92727274\n",
      "epoch: 696 - cost: 0.19734555 -MSE: 7.536893106002264 -Train Accuracy: 0.93333334\n",
      "epoch: 697 - cost: 0.19169936 -MSE: 8.359743858035271 -Train Accuracy: 0.93333334\n",
      "epoch: 698 - cost: 0.19014242 -MSE: 7.889683231809944 -Train Accuracy: 0.92121214\n",
      "epoch: 699 - cost: 0.1916999 -MSE: 9.33361779370301 -Train Accuracy: 0.93939394\n",
      "epoch: 700 - cost: 0.21253519 -MSE: 7.939934123026376 -Train Accuracy: 0.92121214\n",
      "epoch: 701 - cost: 0.3079745 -MSE: 12.243412504693717 -Train Accuracy: 0.8666667\n",
      "epoch: 702 - cost: 0.6913485 -MSE: 6.748920642591808 -Train Accuracy: 0.73333335\n",
      "epoch: 703 - cost: 0.42789134 -MSE: 12.021832001421144 -Train Accuracy: 0.77575755\n",
      "epoch: 704 - cost: 0.42486095 -MSE: 2.7452672300015815 -Train Accuracy: 0.73939395\n",
      "epoch: 705 - cost: 0.25661385 -MSE: 5.760532750739283 -Train Accuracy: 0.92727274\n",
      "epoch: 706 - cost: 0.21546021 -MSE: 7.292145191486004 -Train Accuracy: 0.92121214\n",
      "epoch: 707 - cost: 0.19689237 -MSE: 8.487958622078049 -Train Accuracy: 0.93939394\n",
      "epoch: 708 - cost: 0.18815607 -MSE: 8.581247365292633 -Train Accuracy: 0.92727274\n",
      "epoch: 709 - cost: 0.18636766 -MSE: 10.377830203493888 -Train Accuracy: 0.94545454\n",
      "epoch: 710 - cost: 0.19924675 -MSE: 8.76076132749843 -Train Accuracy: 0.92727274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 711 - cost: 0.29511464 -MSE: 15.16397701027764 -Train Accuracy: 0.8787879\n",
      "epoch: 712 - cost: 0.6930254 -MSE: 6.389815869243721 -Train Accuracy: 0.73333335\n",
      "epoch: 713 - cost: 0.42942238 -MSE: 12.94677104054198 -Train Accuracy: 0.7818182\n",
      "epoch: 714 - cost: 0.4109424 -MSE: 2.6283906734595104 -Train Accuracy: 0.73939395\n",
      "epoch: 715 - cost: 0.26794863 -MSE: 5.3415849365531995 -Train Accuracy: 0.9030303\n",
      "epoch: 716 - cost: 0.21489346 -MSE: 7.061307014704956 -Train Accuracy: 0.92727274\n",
      "epoch: 717 - cost: 0.19305155 -MSE: 8.378097515312374 -Train Accuracy: 0.93939394\n",
      "epoch: 718 - cost: 0.1830497 -MSE: 8.64069007861877 -Train Accuracy: 0.92727274\n",
      "epoch: 719 - cost: 0.18108411 -MSE: 10.357669230636182 -Train Accuracy: 0.94545454\n",
      "epoch: 720 - cost: 0.18902344 -MSE: 8.994329882522205 -Train Accuracy: 0.92121214\n",
      "epoch: 721 - cost: 0.25126415 -MSE: 14.208238108320753 -Train Accuracy: 0.8848485\n",
      "epoch: 722 - cost: 0.5090712 -MSE: 6.696609015791412 -Train Accuracy: 0.7878788\n",
      "epoch: 723 - cost: 0.39270684 -MSE: 13.696103017662423 -Train Accuracy: 0.8181818\n",
      "epoch: 724 - cost: 0.4401418 -MSE: 3.1607490707627153 -Train Accuracy: 0.73333335\n",
      "epoch: 725 - cost: 0.2534934 -MSE: 5.8721147308281525 -Train Accuracy: 0.93333334\n",
      "epoch: 726 - cost: 0.20371632 -MSE: 6.987544836935329 -Train Accuracy: 0.92727274\n",
      "epoch: 727 - cost: 0.186532 -MSE: 8.156973575294181 -Train Accuracy: 0.93939394\n",
      "epoch: 728 - cost: 0.17909421 -MSE: 8.259277683495913 -Train Accuracy: 0.92727274\n",
      "epoch: 729 - cost: 0.17919688 -MSE: 10.000790845458644 -Train Accuracy: 0.94545454\n",
      "epoch: 730 - cost: 0.19628374 -MSE: 8.500349795778423 -Train Accuracy: 0.92121214\n",
      "epoch: 731 - cost: 0.25993916 -MSE: 12.92391963392889 -Train Accuracy: 0.8909091\n",
      "epoch: 732 - cost: 0.5594885 -MSE: 6.822363315959176 -Train Accuracy: 0.76363635\n",
      "epoch: 733 - cost: 0.3930098 -MSE: 11.91703906692618 -Train Accuracy: 0.8060606\n",
      "epoch: 734 - cost: 0.37414274 -MSE: 3.0324417042983254 -Train Accuracy: 0.75757575\n",
      "epoch: 735 - cost: 0.2372787 -MSE: 6.447027434362992 -Train Accuracy: 0.93333334\n",
      "epoch: 736 - cost: 0.19314986 -MSE: 7.541222323296714 -Train Accuracy: 0.92727274\n",
      "epoch: 737 - cost: 0.1793694 -MSE: 9.161778571579134 -Train Accuracy: 0.94545454\n",
      "epoch: 738 - cost: 0.18595913 -MSE: 8.310651254180724 -Train Accuracy: 0.92727274\n",
      "epoch: 739 - cost: 0.19200706 -MSE: 11.185150484243737 -Train Accuracy: 0.92727274\n",
      "epoch: 740 - cost: 0.28194186 -MSE: 7.866091005873043 -Train Accuracy: 0.8545455\n",
      "epoch: 741 - cost: 0.3993621 -MSE: 14.357112690534203 -Train Accuracy: 0.8181818\n",
      "epoch: 742 - cost: 0.7238568 -MSE: 5.388675856817762 -Train Accuracy: 0.6727273\n",
      "epoch: 743 - cost: 0.338569 -MSE: 7.107578305489516 -Train Accuracy: 0.92727274\n",
      "epoch: 744 - cost: 0.26926902 -MSE: 7.117913735812879 -Train Accuracy: 0.92121214\n",
      "epoch: 745 - cost: 0.21039678 -MSE: 7.967240887248947 -Train Accuracy: 0.93939394\n",
      "epoch: 746 - cost: 0.17612842 -MSE: 9.000972748995036 -Train Accuracy: 0.93333334\n",
      "epoch: 747 - cost: 0.16358048 -MSE: 10.618777606545889 -Train Accuracy: 0.94545454\n",
      "epoch: 748 - cost: 0.16201568 -MSE: 10.38671838707234 -Train Accuracy: 0.93333334\n",
      "epoch: 749 - cost: 0.18051943 -MSE: 13.514643800393571 -Train Accuracy: 0.93333334\n",
      "epoch: 750 - cost: 0.29543403 -MSE: 8.952031867102065 -Train Accuracy: 0.8424242\n",
      "epoch: 751 - cost: 0.41707024 -MSE: 17.122869108911637 -Train Accuracy: 0.8060606\n",
      "epoch: 752 - cost: 0.78026706 -MSE: 6.085320159628152 -Train Accuracy: 0.6666667\n",
      "epoch: 753 - cost: 0.33767518 -MSE: 6.2742056210349615 -Train Accuracy: 0.92727274\n",
      "epoch: 754 - cost: 0.27368495 -MSE: 7.45701797445612 -Train Accuracy: 0.92727274\n",
      "epoch: 755 - cost: 0.22367202 -MSE: 7.8619029550101125 -Train Accuracy: 0.92727274\n",
      "epoch: 756 - cost: 0.18452379 -MSE: 8.767129167528593 -Train Accuracy: 0.93333334\n",
      "epoch: 757 - cost: 0.1628858 -MSE: 10.364712949585606 -Train Accuracy: 0.93939394\n",
      "epoch: 758 - cost: 0.1546799 -MSE: 11.104953318321988 -Train Accuracy: 0.93333334\n",
      "epoch: 759 - cost: 0.15445325 -MSE: 12.678809658294751 -Train Accuracy: 0.94545454\n",
      "epoch: 760 - cost: 0.180365 -MSE: 10.59404398744845 -Train Accuracy: 0.92727274\n",
      "epoch: 761 - cost: 0.3153546 -MSE: 18.967737351651895 -Train Accuracy: 0.8606061\n",
      "epoch: 762 - cost: 0.8707575 -MSE: 8.43938919296151 -Train Accuracy: 0.6969697\n",
      "epoch: 763 - cost: 0.34998137 -MSE: 11.713306731807041 -Train Accuracy: 0.8666667\n",
      "epoch: 764 - cost: 0.3094542 -MSE: 4.182830087765204 -Train Accuracy: 0.8363636\n",
      "epoch: 765 - cost: 0.23575379 -MSE: 6.442991269017064 -Train Accuracy: 0.92121214\n",
      "epoch: 766 - cost: 0.19231103 -MSE: 9.817334830898774 -Train Accuracy: 0.94545454\n",
      "epoch: 767 - cost: 0.18490475 -MSE: 8.459118101741067 -Train Accuracy: 0.92727274\n",
      "epoch: 768 - cost: 0.19057828 -MSE: 12.807478747438408 -Train Accuracy: 0.92727274\n",
      "epoch: 769 - cost: 0.28420243 -MSE: 7.816444845567289 -Train Accuracy: 0.8424242\n",
      "epoch: 770 - cost: 0.27938384 -MSE: 14.28497456519393 -Train Accuracy: 0.8787879\n",
      "epoch: 771 - cost: 0.4837678 -MSE: 5.821083417339514 -Train Accuracy: 0.75151515\n",
      "epoch: 772 - cost: 0.24947496 -MSE: 9.928382293273993 -Train Accuracy: 0.92121214\n",
      "epoch: 773 - cost: 0.22242485 -MSE: 6.594766253620473 -Train Accuracy: 0.9030303\n",
      "epoch: 774 - cost: 0.17821148 -MSE: 10.774515185620704 -Train Accuracy: 0.95151514\n",
      "epoch: 775 - cost: 0.19380023 -MSE: 8.57726434815019 -Train Accuracy: 0.91515154\n",
      "epoch: 776 - cost: 0.22189151 -MSE: 14.368468625988411 -Train Accuracy: 0.9030303\n",
      "epoch: 777 - cost: 0.382708 -MSE: 7.000753140941567 -Train Accuracy: 0.8181818\n",
      "epoch: 778 - cost: 0.22883455 -MSE: 11.871069253545746 -Train Accuracy: 0.90909094\n",
      "epoch: 779 - cost: 0.24904734 -MSE: 6.389993681654149 -Train Accuracy: 0.8424242\n",
      "epoch: 780 - cost: 0.17639023 -MSE: 10.493898195953228 -Train Accuracy: 0.95151514\n",
      "epoch: 781 - cost: 0.17549749 -MSE: 9.030599955599433 -Train Accuracy: 0.93333334\n",
      "epoch: 782 - cost: 0.20168103 -MSE: 14.419018825410651 -Train Accuracy: 0.91515154\n",
      "epoch: 783 - cost: 0.34624568 -MSE: 7.62825418883741 -Train Accuracy: 0.830303\n",
      "epoch: 784 - cost: 0.23981702 -MSE: 13.187503144270016 -Train Accuracy: 0.8848485\n",
      "epoch: 785 - cost: 0.30536404 -MSE: 6.059851009528163 -Train Accuracy: 0.8242424\n",
      "epoch: 786 - cost: 0.18238556 -MSE: 9.87262918675689 -Train Accuracy: 0.95151514\n",
      "epoch: 787 - cost: 0.15515774 -MSE: 10.096063200298019 -Train Accuracy: 0.94545454\n",
      "epoch: 788 - cost: 0.14918208 -MSE: 12.032779073686312 -Train Accuracy: 0.95151514\n",
      "epoch: 789 - cost: 0.1661335 -MSE: 10.18838900548641 -Train Accuracy: 0.93333334\n",
      "epoch: 790 - cost: 0.23061216 -MSE: 16.861317458772255 -Train Accuracy: 0.8909091\n",
      "epoch: 791 - cost: 0.5320214 -MSE: 7.692038891136666 -Train Accuracy: 0.77575755\n",
      "epoch: 792 - cost: 0.40270147 -MSE: 15.97110313738153 -Train Accuracy: 0.8242424\n",
      "epoch: 793 - cost: 0.4450618 -MSE: 3.1550627036107732 -Train Accuracy: 0.6969697\n",
      "epoch: 794 - cost: 0.2605645 -MSE: 5.56737849592749 -Train Accuracy: 0.8848485\n",
      "epoch: 795 - cost: 0.19338329 -MSE: 7.542921586633024 -Train Accuracy: 0.93333334\n",
      "epoch: 796 - cost: 0.1640615 -MSE: 8.651494354780784 -Train Accuracy: 0.93333334\n",
      "epoch: 797 - cost: 0.15448321 -MSE: 10.068670924117379 -Train Accuracy: 0.95151514\n",
      "epoch: 798 - cost: 0.1560925 -MSE: 9.237432531854253 -Train Accuracy: 0.93333334\n",
      "epoch: 799 - cost: 0.16764832 -MSE: 12.10078045985182 -Train Accuracy: 0.93939394\n",
      "epoch: 800 - cost: 0.2416579 -MSE: 8.5177496392518 -Train Accuracy: 0.8787879\n",
      "epoch: 801 - cost: 0.3087496 -MSE: 14.791866855904491 -Train Accuracy: 0.8666667\n",
      "epoch: 802 - cost: 0.57386655 -MSE: 6.446420760716519 -Train Accuracy: 0.73939395\n",
      "epoch: 803 - cost: 0.32724348 -MSE: 11.4818869826042 -Train Accuracy: 0.8848485\n",
      "epoch: 804 - cost: 0.25920865 -MSE: 5.01238260124356 -Train Accuracy: 0.8666667\n",
      "epoch: 805 - cost: 0.19743532 -MSE: 7.254140914002459 -Train Accuracy: 0.93939394\n",
      "epoch: 806 - cost: 0.15888862 -MSE: 9.126325356796377 -Train Accuracy: 0.93939394\n",
      "epoch: 807 - cost: 0.14385684 -MSE: 10.471786673720143 -Train Accuracy: 0.95151514\n",
      "epoch: 808 - cost: 0.14123636 -MSE: 10.410241789414494 -Train Accuracy: 0.94545454\n",
      "epoch: 809 - cost: 0.14582634 -MSE: 12.489813968486297 -Train Accuracy: 0.95151514\n",
      "epoch: 810 - cost: 0.18644316 -MSE: 9.921025540762978 -Train Accuracy: 0.92727274\n",
      "epoch: 811 - cost: 0.27544603 -MSE: 17.070678924704858 -Train Accuracy: 0.8848485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 812 - cost: 0.67185104 -MSE: 7.994396374146788 -Train Accuracy: 0.73333335\n",
      "epoch: 813 - cost: 0.42928323 -MSE: 14.308072979349468 -Train Accuracy: 0.7939394\n",
      "epoch: 814 - cost: 0.37449878 -MSE: 2.674087628445385 -Train Accuracy: 0.75757575\n",
      "epoch: 815 - cost: 0.2539809 -MSE: 5.398641242818099 -Train Accuracy: 0.8666667\n",
      "epoch: 816 - cost: 0.19259347 -MSE: 7.01697288764651 -Train Accuracy: 0.93939394\n",
      "epoch: 817 - cost: 0.15563108 -MSE: 8.711921686541695 -Train Accuracy: 0.94545454\n",
      "epoch: 818 - cost: 0.14362484 -MSE: 9.472961548830174 -Train Accuracy: 0.94545454\n",
      "epoch: 819 - cost: 0.13917813 -MSE: 10.451280480450285 -Train Accuracy: 0.95151514\n",
      "epoch: 820 - cost: 0.14015143 -MSE: 9.97676108417488 -Train Accuracy: 0.93939394\n",
      "epoch: 821 - cost: 0.15375623 -MSE: 12.432904938886427 -Train Accuracy: 0.93333334\n",
      "epoch: 822 - cost: 0.21436976 -MSE: 9.111761094696671 -Train Accuracy: 0.8909091\n",
      "epoch: 823 - cost: 0.23907256 -MSE: 13.92083895058877 -Train Accuracy: 0.8909091\n",
      "epoch: 824 - cost: 0.49361333 -MSE: 7.607427724145975 -Train Accuracy: 0.7878788\n",
      "epoch: 825 - cost: 0.30797958 -MSE: 12.109056298696846 -Train Accuracy: 0.8727273\n",
      "epoch: 826 - cost: 0.2676171 -MSE: 4.7475168232833225 -Train Accuracy: 0.830303\n",
      "epoch: 827 - cost: 0.18647563 -MSE: 7.603922835681745 -Train Accuracy: 0.93939394\n",
      "epoch: 828 - cost: 0.14898568 -MSE: 9.217924353740509 -Train Accuracy: 0.94545454\n",
      "epoch: 829 - cost: 0.13710284 -MSE: 11.249299510628086 -Train Accuracy: 0.95151514\n",
      "epoch: 830 - cost: 0.14206798 -MSE: 10.229191691830149 -Train Accuracy: 0.93939394\n",
      "epoch: 831 - cost: 0.16585056 -MSE: 13.680857085019792 -Train Accuracy: 0.92727274\n",
      "epoch: 832 - cost: 0.2978757 -MSE: 9.037919997557472 -Train Accuracy: 0.8363636\n",
      "epoch: 833 - cost: 0.43039647 -MSE: 16.94594768323135 -Train Accuracy: 0.8121212\n",
      "epoch: 834 - cost: 0.71123105 -MSE: 5.941550972867406 -Train Accuracy: 0.6606061\n",
      "epoch: 835 - cost: 0.3609717 -MSE: 6.727699229712989 -Train Accuracy: 0.8787879\n",
      "epoch: 836 - cost: 0.25376993 -MSE: 7.61287999119026 -Train Accuracy: 0.93333334\n",
      "epoch: 837 - cost: 0.18905565 -MSE: 8.514082686830788 -Train Accuracy: 0.93939394\n",
      "epoch: 838 - cost: 0.15651493 -MSE: 9.825862966587422 -Train Accuracy: 0.94545454\n",
      "epoch: 839 - cost: 0.14159112 -MSE: 10.130356712532036 -Train Accuracy: 0.93939394\n",
      "epoch: 840 - cost: 0.14169429 -MSE: 12.300219542139608 -Train Accuracy: 0.95151514\n",
      "epoch: 841 - cost: 0.16859086 -MSE: 10.760275520292955 -Train Accuracy: 0.93333334\n",
      "epoch: 842 - cost: 0.27352062 -MSE: 17.05989394833401 -Train Accuracy: 0.8848485\n",
      "epoch: 843 - cost: 0.6185116 -MSE: 9.954317099976151 -Train Accuracy: 0.74545455\n",
      "epoch: 844 - cost: 0.36427125 -MSE: 13.689726626918574 -Train Accuracy: 0.8181818\n",
      "epoch: 845 - cost: 0.34542245 -MSE: 3.2866916730418545 -Train Accuracy: 0.7818182\n",
      "epoch: 846 - cost: 0.2208862 -MSE: 6.81150860562705 -Train Accuracy: 0.90909094\n",
      "epoch: 847 - cost: 0.16579625 -MSE: 9.07833086922652 -Train Accuracy: 0.95151514\n",
      "epoch: 848 - cost: 0.1394453 -MSE: 10.267092572613244 -Train Accuracy: 0.95151514\n",
      "epoch: 849 - cost: 0.12911017 -MSE: 10.953820741956223 -Train Accuracy: 0.95151514\n",
      "epoch: 850 - cost: 0.1241143 -MSE: 11.633275466882202 -Train Accuracy: 0.95151514\n",
      "epoch: 851 - cost: 0.12105915 -MSE: 12.011910888752876 -Train Accuracy: 0.95151514\n",
      "epoch: 852 - cost: 0.118912995 -MSE: 12.770965454599702 -Train Accuracy: 0.94545454\n",
      "epoch: 853 - cost: 0.118089296 -MSE: 12.66124059687262 -Train Accuracy: 0.95151514\n",
      "epoch: 854 - cost: 0.12073263 -MSE: 13.963250871854354 -Train Accuracy: 0.95151514\n",
      "epoch: 855 - cost: 0.1437577 -MSE: 11.903712849045096 -Train Accuracy: 0.93939394\n",
      "epoch: 856 - cost: 0.2708416 -MSE: 18.722685477191924 -Train Accuracy: 0.8909091\n",
      "epoch: 857 - cost: 0.79812384 -MSE: 10.257719083975534 -Train Accuracy: 0.7151515\n",
      "epoch: 858 - cost: 0.5289045 -MSE: 16.174762411488874 -Train Accuracy: 0.74545455\n",
      "epoch: 859 - cost: 0.49189574 -MSE: 2.009531941205986 -Train Accuracy: 0.6909091\n",
      "epoch: 860 - cost: 0.30147105 -MSE: 4.2360986442907755 -Train Accuracy: 0.8242424\n",
      "epoch: 861 - cost: 0.23583762 -MSE: 6.239199266181138 -Train Accuracy: 0.8727273\n",
      "epoch: 862 - cost: 0.18230265 -MSE: 8.242704923376518 -Train Accuracy: 0.93939394\n",
      "epoch: 863 - cost: 0.15017812 -MSE: 9.596653515901167 -Train Accuracy: 0.94545454\n",
      "epoch: 864 - cost: 0.13312449 -MSE: 10.852696830053198 -Train Accuracy: 0.96363634\n",
      "epoch: 865 - cost: 0.12683094 -MSE: 10.865011748498395 -Train Accuracy: 0.94545454\n",
      "epoch: 866 - cost: 0.12756193 -MSE: 11.984102695407618 -Train Accuracy: 0.95151514\n",
      "epoch: 867 - cost: 0.14384688 -MSE: 10.673059281993936 -Train Accuracy: 0.94545454\n",
      "epoch: 868 - cost: 0.20889759 -MSE: 15.634748536947345 -Train Accuracy: 0.90909094\n",
      "epoch: 869 - cost: 0.48239705 -MSE: 8.835007189930748 -Train Accuracy: 0.8060606\n",
      "epoch: 870 - cost: 0.30406472 -MSE: 13.431726391773045 -Train Accuracy: 0.8545455\n",
      "epoch: 871 - cost: 0.27473032 -MSE: 5.035751284046352 -Train Accuracy: 0.830303\n",
      "epoch: 872 - cost: 0.18405454 -MSE: 7.607798809882039 -Train Accuracy: 0.94545454\n",
      "epoch: 873 - cost: 0.14176886 -MSE: 9.842764660656627 -Train Accuracy: 0.95151514\n",
      "epoch: 874 - cost: 0.12183712 -MSE: 10.789240415690884 -Train Accuracy: 0.95757574\n",
      "epoch: 875 - cost: 0.11535877 -MSE: 11.744539415523775 -Train Accuracy: 0.95757574\n",
      "epoch: 876 - cost: 0.11206792 -MSE: 12.028475734561136 -Train Accuracy: 0.95151514\n",
      "epoch: 877 - cost: 0.11172058 -MSE: 12.807130418025096 -Train Accuracy: 0.96363634\n",
      "epoch: 878 - cost: 0.11992972 -MSE: 12.040410120089929 -Train Accuracy: 0.94545454\n",
      "epoch: 879 - cost: 0.16414924 -MSE: 16.004164560654928 -Train Accuracy: 0.92727274\n",
      "epoch: 880 - cost: 0.38597575 -MSE: 9.84407677003469 -Train Accuracy: 0.8363636\n",
      "epoch: 881 - cost: 0.3063069 -MSE: 14.92888831270847 -Train Accuracy: 0.8484849\n",
      "epoch: 882 - cost: 0.38085735 -MSE: 5.658324438699506 -Train Accuracy: 0.76969695\n",
      "epoch: 883 - cost: 0.2016924 -MSE: 9.28235453023818 -Train Accuracy: 0.969697\n",
      "epoch: 884 - cost: 0.1393061 -MSE: 9.889841781703794 -Train Accuracy: 0.95151514\n",
      "epoch: 885 - cost: 0.11849799 -MSE: 11.693289538667251 -Train Accuracy: 0.96363634\n",
      "epoch: 886 - cost: 0.1189349 -MSE: 11.442914674590797 -Train Accuracy: 0.94545454\n",
      "epoch: 887 - cost: 0.14734107 -MSE: 14.95840435749117 -Train Accuracy: 0.93333334\n",
      "epoch: 888 - cost: 0.28380495 -MSE: 9.923148250633863 -Train Accuracy: 0.8424242\n",
      "epoch: 889 - cost: 0.3655017 -MSE: 16.640476502846482 -Train Accuracy: 0.8363636\n",
      "epoch: 890 - cost: 0.60324824 -MSE: 6.465908820242558 -Train Accuracy: 0.6848485\n",
      "epoch: 891 - cost: 0.3247576 -MSE: 9.060456422547134 -Train Accuracy: 0.8727273\n",
      "epoch: 892 - cost: 0.20355634 -MSE: 8.464044586312493 -Train Accuracy: 0.95757574\n",
      "epoch: 893 - cost: 0.14762567 -MSE: 9.818208353083781 -Train Accuracy: 0.95151514\n",
      "epoch: 894 - cost: 0.12623776 -MSE: 10.821041925359149 -Train Accuracy: 0.96363634\n",
      "epoch: 895 - cost: 0.11515934 -MSE: 12.16577641816295 -Train Accuracy: 0.96363634\n",
      "epoch: 896 - cost: 0.11105408 -MSE: 12.118552802113305 -Train Accuracy: 0.96363634\n",
      "epoch: 897 - cost: 0.11690226 -MSE: 14.50241715536108 -Train Accuracy: 0.95151514\n",
      "epoch: 898 - cost: 0.16885437 -MSE: 11.751150635102194 -Train Accuracy: 0.92727274\n",
      "epoch: 899 - cost: 0.34934586 -MSE: 20.040643098325322 -Train Accuracy: 0.8424242\n",
      "epoch: 900 - cost: 0.93130493 -MSE: 10.306999651341087 -Train Accuracy: 0.6666667\n",
      "epoch: 901 - cost: 0.37029368 -MSE: 10.168037805901092 -Train Accuracy: 0.8121212\n",
      "epoch: 902 - cost: 0.27883402 -MSE: 6.330516673575126 -Train Accuracy: 0.92121214\n",
      "epoch: 903 - cost: 0.21140204 -MSE: 9.972519742757523 -Train Accuracy: 0.96363634\n",
      "epoch: 904 - cost: 0.166087 -MSE: 10.510750945406752 -Train Accuracy: 0.969697\n",
      "epoch: 905 - cost: 0.13626917 -MSE: 11.52471824139392 -Train Accuracy: 0.95757574\n",
      "epoch: 906 - cost: 0.11901319 -MSE: 12.62316395136285 -Train Accuracy: 0.95757574\n",
      "epoch: 907 - cost: 0.11097023 -MSE: 13.524815469574378 -Train Accuracy: 0.969697\n",
      "epoch: 908 - cost: 0.106833175 -MSE: 13.750575911507038 -Train Accuracy: 0.969697\n",
      "epoch: 909 - cost: 0.10925908 -MSE: 15.623486464818484 -Train Accuracy: 0.95151514\n",
      "epoch: 910 - cost: 0.13518512 -MSE: 12.935793212664954 -Train Accuracy: 0.94545454\n",
      "epoch: 911 - cost: 0.2516028 -MSE: 21.17795210180615 -Train Accuracy: 0.8969697\n",
      "epoch: 912 - cost: 0.7160273 -MSE: 10.322365196319236 -Train Accuracy: 0.72727275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 913 - cost: 0.30485627 -MSE: 15.537015906571748 -Train Accuracy: 0.8787879\n",
      "epoch: 914 - cost: 0.2787409 -MSE: 5.320607608986127 -Train Accuracy: 0.830303\n",
      "epoch: 915 - cost: 0.19451217 -MSE: 8.344265365684848 -Train Accuracy: 0.92121214\n",
      "epoch: 916 - cost: 0.13430552 -MSE: 12.044431907297266 -Train Accuracy: 0.969697\n",
      "epoch: 917 - cost: 0.11671244 -MSE: 12.063606187345618 -Train Accuracy: 0.96363634\n",
      "epoch: 918 - cost: 0.11216239 -MSE: 14.38165548230033 -Train Accuracy: 0.96363634\n",
      "epoch: 919 - cost: 0.13071696 -MSE: 12.255249368390285 -Train Accuracy: 0.95151514\n",
      "epoch: 920 - cost: 0.20019984 -MSE: 19.070407430561925 -Train Accuracy: 0.91515154\n",
      "epoch: 921 - cost: 0.509217 -MSE: 9.924095020772835 -Train Accuracy: 0.8\n",
      "epoch: 922 - cost: 0.22966067 -MSE: 14.878792900275348 -Train Accuracy: 0.92121214\n",
      "epoch: 923 - cost: 0.23307544 -MSE: 7.442886100090424 -Train Accuracy: 0.8484849\n",
      "epoch: 924 - cost: 0.13400266 -MSE: 11.998485902018 -Train Accuracy: 0.95151514\n",
      "epoch: 925 - cost: 0.11306285 -MSE: 13.952958600466264 -Train Accuracy: 0.969697\n",
      "epoch: 926 - cost: 0.10418972 -MSE: 13.444098174591474 -Train Accuracy: 0.969697\n",
      "epoch: 927 - cost: 0.10205042 -MSE: 15.152818748978172 -Train Accuracy: 0.96363634\n",
      "epoch: 928 - cost: 0.111449674 -MSE: 13.111179423428005 -Train Accuracy: 0.95757574\n",
      "epoch: 929 - cost: 0.14940977 -MSE: 18.02962389313778 -Train Accuracy: 0.92727274\n",
      "epoch: 930 - cost: 0.35390577 -MSE: 10.514704475634673 -Train Accuracy: 0.8363636\n",
      "epoch: 931 - cost: 0.26458034 -MSE: 17.26727077785211 -Train Accuracy: 0.8848485\n",
      "epoch: 932 - cost: 0.3503532 -MSE: 7.2916570318545055 -Train Accuracy: 0.8121212\n",
      "epoch: 933 - cost: 0.15191253 -MSE: 11.678695320542943 -Train Accuracy: 0.9878788\n",
      "epoch: 934 - cost: 0.116682455 -MSE: 12.885221765886737 -Train Accuracy: 0.95757574\n",
      "epoch: 935 - cost: 0.10177512 -MSE: 13.912537570467505 -Train Accuracy: 0.95757574\n",
      "epoch: 936 - cost: 0.095551886 -MSE: 14.362168947330685 -Train Accuracy: 0.96363634\n",
      "epoch: 937 - cost: 0.09227866 -MSE: 14.48453549248222 -Train Accuracy: 0.96363634\n",
      "epoch: 938 - cost: 0.090096205 -MSE: 15.3149933994387 -Train Accuracy: 0.96363634\n",
      "epoch: 939 - cost: 0.08935579 -MSE: 14.669727588737747 -Train Accuracy: 0.96363634\n",
      "epoch: 940 - cost: 0.09650111 -MSE: 17.004645539370408 -Train Accuracy: 0.95151514\n",
      "epoch: 941 - cost: 0.14489682 -MSE: 13.193026527897635 -Train Accuracy: 0.94545454\n",
      "epoch: 942 - cost: 0.31541923 -MSE: 23.396631868289862 -Train Accuracy: 0.8727273\n",
      "epoch: 943 - cost: 0.9909407 -MSE: 10.783896672073197 -Train Accuracy: 0.6666667\n",
      "epoch: 944 - cost: 0.4980096 -MSE: 16.200823249393434 -Train Accuracy: 0.6909091\n",
      "epoch: 945 - cost: 0.3015785 -MSE: 4.844313806138454 -Train Accuracy: 0.8424242\n",
      "epoch: 946 - cost: 0.23567471 -MSE: 7.111373576579056 -Train Accuracy: 0.8787879\n",
      "epoch: 947 - cost: 0.16634995 -MSE: 10.027527912506896 -Train Accuracy: 0.95151514\n",
      "epoch: 948 - cost: 0.13327911 -MSE: 14.398071198053334 -Train Accuracy: 0.96363634\n",
      "epoch: 949 - cost: 0.12691416 -MSE: 12.063120978604786 -Train Accuracy: 0.95151514\n",
      "epoch: 950 - cost: 0.14258255 -MSE: 18.13343190604334 -Train Accuracy: 0.94545454\n",
      "epoch: 951 - cost: 0.25093815 -MSE: 10.41306928066293 -Train Accuracy: 0.8545455\n",
      "epoch: 952 - cost: 0.2054808 -MSE: 17.21548322621151 -Train Accuracy: 0.91515154\n",
      "epoch: 953 - cost: 0.29177007 -MSE: 8.481466216652596 -Train Accuracy: 0.830303\n",
      "epoch: 954 - cost: 0.12719715 -MSE: 13.312543521537695 -Train Accuracy: 0.969697\n",
      "epoch: 955 - cost: 0.10918967 -MSE: 12.717439121758783 -Train Accuracy: 0.969697\n",
      "epoch: 956 - cost: 0.099951245 -MSE: 15.852670163128375 -Train Accuracy: 0.96363634\n",
      "epoch: 957 - cost: 0.10584578 -MSE: 13.427878074290643 -Train Accuracy: 0.96363634\n",
      "epoch: 958 - cost: 0.12931766 -MSE: 18.39908792315768 -Train Accuracy: 0.93939394\n",
      "epoch: 959 - cost: 0.24370952 -MSE: 11.603160870002531 -Train Accuracy: 0.8606061\n",
      "epoch: 960 - cost: 0.20341048 -MSE: 19.427043667565414 -Train Accuracy: 0.90909094\n",
      "epoch: 961 - cost: 0.38619083 -MSE: 8.890168131287954 -Train Accuracy: 0.8121212\n",
      "epoch: 962 - cost: 0.16360314 -MSE: 13.944767028501758 -Train Accuracy: 0.95757574\n",
      "epoch: 963 - cost: 0.14021319 -MSE: 10.463179368425823 -Train Accuracy: 0.95151514\n",
      "epoch: 964 - cost: 0.11657577 -MSE: 15.628961002852883 -Train Accuracy: 0.95757574\n",
      "epoch: 965 - cost: 0.14980242 -MSE: 11.197504741023133 -Train Accuracy: 0.94545454\n",
      "epoch: 966 - cost: 0.17822216 -MSE: 18.44963635370353 -Train Accuracy: 0.92727274\n",
      "epoch: 967 - cost: 0.38851985 -MSE: 9.328006500607344 -Train Accuracy: 0.8181818\n",
      "epoch: 968 - cost: 0.18681143 -MSE: 14.922284756238222 -Train Accuracy: 0.92727274\n",
      "epoch: 969 - cost: 0.18498026 -MSE: 8.74626221386349 -Train Accuracy: 0.8909091\n",
      "epoch: 970 - cost: 0.109364495 -MSE: 12.817468496181835 -Train Accuracy: 0.9757576\n",
      "epoch: 971 - cost: 0.093154535 -MSE: 13.493624867315031 -Train Accuracy: 0.969697\n",
      "epoch: 972 - cost: 0.08560592 -MSE: 14.444673407440787 -Train Accuracy: 0.969697\n",
      "epoch: 973 - cost: 0.08215296 -MSE: 14.970927634187747 -Train Accuracy: 0.9757576\n",
      "epoch: 974 - cost: 0.08000414 -MSE: 14.889038085988298 -Train Accuracy: 0.96363634\n",
      "epoch: 975 - cost: 0.079050355 -MSE: 16.046786904403618 -Train Accuracy: 0.9818182\n",
      "epoch: 976 - cost: 0.082592286 -MSE: 14.76182529788472 -Train Accuracy: 0.969697\n",
      "epoch: 977 - cost: 0.09709385 -MSE: 18.068714120158557 -Train Accuracy: 0.95757574\n",
      "epoch: 978 - cost: 0.17882898 -MSE: 12.809679444173495 -Train Accuracy: 0.91515154\n",
      "epoch: 979 - cost: 0.42320797 -MSE: 25.875026801624028 -Train Accuracy: 0.8424242\n",
      "epoch: 980 - cost: 1.273044 -MSE: 11.237484675109792 -Train Accuracy: 0.6363636\n",
      "epoch: 981 - cost: 0.5291504 -MSE: 11.500428284054307 -Train Accuracy: 0.6666667\n",
      "epoch: 982 - cost: 0.26238006 -MSE: 11.18049340412366 -Train Accuracy: 0.8848485\n",
      "epoch: 983 - cost: 0.24834715 -MSE: 15.322782531530565 -Train Accuracy: 0.92121214\n",
      "epoch: 984 - cost: 0.29774138 -MSE: 9.153895056104554 -Train Accuracy: 0.8666667\n",
      "epoch: 985 - cost: 0.24501285 -MSE: 13.90853289430877 -Train Accuracy: 0.90909094\n",
      "epoch: 986 - cost: 0.3277763 -MSE: 7.206626372779099 -Train Accuracy: 0.8181818\n",
      "epoch: 987 - cost: 0.19800244 -MSE: 10.163327024763488 -Train Accuracy: 0.93939394\n",
      "epoch: 988 - cost: 0.18921863 -MSE: 8.756256090279177 -Train Accuracy: 0.91515154\n",
      "epoch: 989 - cost: 0.2082219 -MSE: 13.385159367881906 -Train Accuracy: 0.9030303\n",
      "epoch: 990 - cost: 0.33497873 -MSE: 7.7757943497416155 -Train Accuracy: 0.8242424\n",
      "epoch: 991 - cost: 0.19528517 -MSE: 11.078032798490764 -Train Accuracy: 0.92727274\n",
      "epoch: 992 - cost: 0.18936384 -MSE: 8.009655349493364 -Train Accuracy: 0.9030303\n",
      "epoch: 993 - cost: 0.14351864 -MSE: 11.331673600621523 -Train Accuracy: 0.95151514\n",
      "epoch: 994 - cost: 0.1573916 -MSE: 9.619640782555743 -Train Accuracy: 0.90909094\n",
      "epoch: 995 - cost: 0.1911781 -MSE: 14.151267875958032 -Train Accuracy: 0.91515154\n",
      "epoch: 996 - cost: 0.34514987 -MSE: 8.57718393746 -Train Accuracy: 0.830303\n",
      "epoch: 997 - cost: 0.1913076 -MSE: 11.945209832273251 -Train Accuracy: 0.92727274\n",
      "epoch: 998 - cost: 0.20464054 -MSE: 7.716293623795766 -Train Accuracy: 0.8545455\n",
      "epoch: 999 - cost: 0.12368506 -MSE: 10.837109365681371 -Train Accuracy: 0.96363634\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-230b052e149d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Saved in File\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict = {x : x_train, y_ : y_train})\n",
    "    cost = sess.run(cost_function, feed_dict = {x : x_train, y_ : y_train})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    pred_y = sess.run(y, feed_dict = {x : x_test})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - y_test))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict = {x:x_train, y_:y_train}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch, '-', 'cost:',cost, '-MSE:', mse_, \"-Train Accuracy:\", accuracy)\n",
    "\n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model Saved in File\"%save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_history, 'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument 0.96363634 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 300\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    301\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3478\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3566\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3567\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a float32 into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-46eeaba0da66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0macuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1137\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    303\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    305\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument 0.96363634 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "acuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy:\", (sess.run(accuracy, feed_dict = {x:x_test, y_:y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:10.8371\n"
     ]
    }
   ],
   "source": [
    "pred_y = sess.run(y, feed_dict={x:x_test})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - y_test))\n",
    "print(\"MSE:%.4f\"%sess.run(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
